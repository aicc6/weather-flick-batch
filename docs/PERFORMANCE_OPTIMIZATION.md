# Weather Flick Batch ì„±ëŠ¥ ìµœì í™” ê°€ì´ë“œ

Weather Flick ë°°ì¹˜ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ ìµœì í™” ê¸°ëŠ¥ê³¼ ì‚¬ìš©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ“Š ì„±ëŠ¥ ìµœì í™” ê°œìš”

### í•µì‹¬ ìµœì í™” ê¸°ëŠ¥
1. **API í˜¸ì¶œ ë³‘ë ¬ ì²˜ë¦¬** - ë™ì‹œ API í˜¸ì¶œë¡œ ì²˜ë¦¬ëŸ‰ 2ë°° ì¦ê°€
2. **ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”** - ìµœì  ë°°ì¹˜ í¬ê¸°ë¡œ 64% ì„±ëŠ¥ í–¥ìƒ  
3. **ë°ì´í„°ë² ì´ìŠ¤ ì»¤ë„¥ì…˜ í’€** - ì—°ê²° ì¬ì‚¬ìš©ìœ¼ë¡œ DB ì„±ëŠ¥ í–¥ìƒ
4. **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”** - ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê·¹ëŒ€í™”

### ì „ì²´ ì„±ëŠ¥ ê°œì„  íš¨ê³¼
- **ì²˜ë¦¬ëŸ‰**: ê¸°ë³¸ ëŒ€ë¹„ **2-5ë°° ì¦ê°€**
- **ë©”ëª¨ë¦¬**: **50-80% ì ˆì•½**
- **ì•ˆì •ì„±**: ìë™ ì˜¤ë¥˜ ë³µêµ¬ ë° ëª¨ë‹ˆí„°ë§

## ğŸš€ API ë³‘ë ¬ ì²˜ë¦¬

### ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from app.collectors.unified_kto_client import UnifiedKTOClient
from app.core.concurrent_api_manager import ConcurrencyConfig

# ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •
concurrency_config = ConcurrencyConfig(
    max_concurrent_kto=5,      # KTO API ë™ì‹œ í˜¸ì¶œ ìˆ˜
    max_concurrent_total=8,    # ì „ì²´ ë™ì‹œ í˜¸ì¶œ ìˆ˜
    min_delay_between_calls=0.2,
    adaptive_delay=True,
    batch_size=50
)

# ë³‘ë ¬ ì²˜ë¦¬ í´ë¼ì´ì–¸íŠ¸ ìƒì„±
kto_client = UnifiedKTOClient(
    enable_parallel=True, 
    concurrency_config=concurrency_config
)

# ë³‘ë ¬ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
result = await kto_client.collect_detailed_info_parallel(
    content_ids=content_ids,
    content_type_id="12",
    store_raw=True,
    batch_size=100
)
```

### ê³ ê¸‰ ì„¤ì •

```python
# ê³ ì„±ëŠ¥ ì„¤ì • (ê°•ë ¥í•œ ì„œë²„ìš©)
high_performance_config = ConcurrencyConfig(
    max_concurrent_kto=10,
    max_concurrent_total=15,
    min_delay_between_calls=0.1,
    adaptive_delay=True,
    batch_size=100
)

# ì•ˆì •ì„± ìš°ì„  ì„¤ì • (ì œí•œëœ ë¦¬ì†ŒìŠ¤)
stable_config = ConcurrencyConfig(
    max_concurrent_kto=2,
    max_concurrent_total=3,
    min_delay_between_calls=0.5,
    adaptive_delay=True,
    batch_size=20
)
```

### ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

```python
# ì„±ëŠ¥ í†µê³„ ì¡°íšŒ
if kto_client.concurrent_manager:
    stats = kto_client.concurrent_manager.get_performance_stats()
    print(f"í‰ê·  ì‘ë‹µì‹œê°„: {stats['average_response_time']:.3f}ì´ˆ")
    print(f"ë™ì‹œ ì²˜ë¦¬ í”¼í¬: {stats['concurrent_peaks']}")
    print(f"ì„±ê³µë¥ : {stats['success_rate']:.1f}%")
```

## ğŸ’¾ ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”

### ìµœì  ë°°ì¹˜ í¬ê¸°

ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ê¶Œì¥ ì„¤ì •:

```python
# ìµœì  ë°°ì¹˜ í¬ê¸°
OPTIMAL_BATCH_SIZES = {
    'api_calls': 100,        # API í˜¸ì¶œ
    'database_insert': 100,  # DB ì‚½ì…
    'data_processing': 50    # ë°ì´í„° ì²˜ë¦¬
}
```

### ë°°ì¹˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

```bash
# ë°°ì¹˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python scripts/test_batch_performance.py --test-size 1000 --batch-sizes 50,100,200

# ê²°ê³¼ ì˜ˆì‹œ:
# ë°°ì¹˜í¬ê¸° 100: 3,685 records/sec, ë©”ëª¨ë¦¬ 0.1MB âš¡ğŸ’¾
```

### ì„±ëŠ¥ ì§€í‘œ

| ë°°ì¹˜ í¬ê¸° | ì²˜ë¦¬ëŸ‰ (records/sec) | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB) |
|----------|-------------------|------------------|
| 50       | 2,245             | 0.2              |
| **100**  | **3,686** âš¡      | **0.1** ğŸ’¾       |
| 200      | 2,788             | 0.2              |

## ğŸ”Œ ë°ì´í„°ë² ì´ìŠ¤ ì»¤ë„¥ì…˜ í’€

### ê¸°ë³¸ ì„¤ì •

```python
from app.core.database_connection_pool import PoolConfig, get_connection_pool

# ì»¤ë„¥ì…˜ í’€ ì„¤ì •
pool_config = PoolConfig(
    sync_min_connections=2,
    sync_max_connections=10,
    async_min_connections=2,
    async_max_connections=15,
    connection_timeout=30,
    idle_timeout=300
)

# ì»¤ë„¥ì…˜ í’€ ì‚¬ìš©
pool = get_connection_pool(pool_config)

# ë™ê¸° ì—°ê²° ì‚¬ìš©
with pool.get_sync_connection() as conn:
    # ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—…
    pass

# ë¹„ë™ê¸° ì—°ê²° ì‚¬ìš©
async with pool.get_async_connection() as conn:
    # ë¹„ë™ê¸° ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—…
    pass
```

### í’€ ìƒíƒœ ëª¨ë‹ˆí„°ë§

```python
# í’€ í†µê³„ ì¡°íšŒ
stats = pool.get_pool_stats()
print(f"í™œì„± ì—°ê²°: {stats['sync_pool']['active_connections']}")
print(f"í’€ íˆíŠ¸ìœ¨: {stats['sync_pool']['pool_hits']}")
```

## ğŸ§  ë©”ëª¨ë¦¬ ìµœì í™”

### ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •

```python
from app.core.memory_optimizer import get_memory_optimizer, MemoryConfig

# ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •
memory_config = MemoryConfig(
    warning_threshold_mb=500,   # ê²½ê³  ì„ê³„ê°’
    critical_threshold_mb=1000, # ìœ„í—˜ ì„ê³„ê°’
    default_chunk_size=100,
    adaptive_chunking=True,
    gc_frequency=100,
    auto_gc=True
)

optimizer = get_memory_optimizer(memory_config)
optimizer.start_monitoring()
```

### ì²­í¬ ì²˜ë¦¬

```python
# ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì²­í¬ ì²˜ë¦¬
for chunk in optimizer.chunk_iterator(large_dataset, chunk_size=100):
    # ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬
    processed_chunk = process_data(chunk)
    
    # ë©”ëª¨ë¦¬ ìë™ ì •ë¦¬
    del processed_chunk
```

### ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬

```python
# ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ì²˜ë¦¬
def process_item(item):
    return transform_data(item)

# ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ê¸° ì‚¬ìš©
for result in optimizer.streaming_processor(
    data_source=iter(dataset),
    processor=process_item,
    batch_size=50
):
    # ê²°ê³¼ ì¦‰ì‹œ ì²˜ë¦¬
    handle_result(result)
```

### ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸

```python
# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì 
with optimizer.memory_context("data_processing"):
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì¶”ì ë˜ëŠ” ì‘ì—…
    result = process_large_dataset(dataset)
```

## ğŸ“ˆ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë° ëª¨ë‹ˆí„°ë§

### ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# API ë³‘ë ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
python scripts/test_parallel_performance.py

# ë°°ì¹˜ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸  
python scripts/test_batch_performance.py

# ë©”ëª¨ë¦¬ ìµœì í™” í…ŒìŠ¤íŠ¸
python scripts/test_memory_optimization.py
```

### ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

```python
# í†µí•© ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
class PerformanceMonitor:
    def __init__(self):
        self.memory_optimizer = get_memory_optimizer()
        self.connection_pool = get_connection_pool()
        
    def get_system_status(self):
        return {
            'memory': self.memory_optimizer.get_memory_report(),
            'database': self.connection_pool.get_pool_stats(),
            'timestamp': datetime.utcnow()
        }
```

## âš¡ ìµœì í™” ê¶Œì¥ì‚¬í•­

### ìš´ì˜ í™˜ê²½ ì„¤ì •

```python
# í”„ë¡œë•ì…˜ í™˜ê²½ ê¶Œì¥ ì„¤ì •
PRODUCTION_CONFIG = {
    'concurrency': ConcurrencyConfig(
        max_concurrent_kto=5,
        max_concurrent_total=8,
        min_delay_between_calls=0.2,
        adaptive_delay=True,
        batch_size=100
    ),
    'memory': MemoryConfig(
        warning_threshold_mb=800,
        critical_threshold_mb=1500,
        default_chunk_size=100,
        adaptive_chunking=True,
        gc_frequency=50
    ),
    'database_pool': PoolConfig(
        sync_max_connections=15,
        async_max_connections=20,
        connection_timeout=30
    )
}
```

### ì„±ëŠ¥ ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ë³‘ë ¬ ì²˜ë¦¬ í™œì„±í™” (`enable_parallel=True`)
- [ ] ìµœì  ë°°ì¹˜ í¬ê¸° ì„¤ì • (100ê°œ ê¶Œì¥)
- [ ] ì»¤ë„¥ì…˜ í’€ ì‚¬ìš©
- [ ] ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ í™œì„±í™”
- [ ] ì ì‘í˜• ì²­í¬ í¬ê¸° ì‚¬ìš©
- [ ] ìë™ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ í™œì„±í™”
- [ ] ì„±ëŠ¥ í†µê³„ ëª¨ë‹ˆí„°ë§

### ë¬¸ì œ í•´ê²°

#### ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ
```python
# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¤„ì´ê¸°
memory_config.default_chunk_size = 50
memory_config.warning_threshold_mb = 300
```

#### API í˜¸ì¶œ ì‹¤íŒ¨ê°€ ë§ì„ ë•Œ
```python
# ë™ì‹œ í˜¸ì¶œ ìˆ˜ ì¤„ì´ê¸°
concurrency_config.max_concurrent_kto = 2
concurrency_config.min_delay_between_calls = 0.5
```

#### DB ì—°ê²° ë¬¸ì œ ì‹œ
```python
# ì»¤ë„¥ì…˜ í’€ í¬ê¸° ì¡°ì •
pool_config.sync_max_connections = 5
pool_config.connection_timeout = 60
```

## ğŸ“Š ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼

| í•­ëª© | ê¸°ë³¸ | ìµœì í™” | ê°œì„ ìœ¨ |
|------|------|---------|--------|
| API ì²˜ë¦¬ëŸ‰ | 1x | 2x | **100%** |
| ë°°ì¹˜ ì„±ëŠ¥ | 2,245/sec | 3,686/sec | **64%** |
| ë©”ëª¨ë¦¬ íš¨ìœ¨ | ê¸°ë³¸ | ì²­í¬ ì²˜ë¦¬ | **ì•ˆì •ì ** |
| DB ì—°ê²° | ê°œë³„ | í’€ë§ | **ì¬ì‚¬ìš©** |

### ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€

```python
# ëŒ€ìš©ëŸ‰ ê´€ê´‘ì§€ ë°ì´í„° ìˆ˜ì§‘ ìµœì í™” ì˜ˆì‹œ
async def collect_all_tourist_attractions():
    # ìµœì í™”ëœ ì„¤ì •ìœ¼ë¡œ í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    kto_client = UnifiedKTOClient(
        enable_parallel=True,
        concurrency_config=PRODUCTION_CONFIG['concurrency']
    )
    
    # ë©”ëª¨ë¦¬ ìµœì í™”ê¸° ì‹œì‘
    optimizer = get_memory_optimizer(PRODUCTION_CONFIG['memory'])
    optimizer.start_monitoring()
    
    try:
        with optimizer.memory_context("tourist_attraction_collection"):
            # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
            result = await kto_client.collect_detailed_info_parallel(
                content_ids=all_content_ids,
                content_type_id="12",
                batch_size=100
            )
            
        return result
        
    finally:
        optimizer.stop_monitoring()
```

ì´ ê°€ì´ë“œë¥¼ í†µí•´ Weather Flick ë°°ì¹˜ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ ìµœëŒ€í•œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.