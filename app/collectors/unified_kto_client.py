"""
í†µí•© KTO API í´ë¼ì´ì–¸íŠ¸

ê¸°ì¡´ KTO API ìˆ˜ì§‘ê¸°ë¥¼ ìƒˆë¡œìš´ í†µí•© ì•„í‚¤í…ì²˜ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜
"""

import logging
import asyncio
from datetime import datetime
from typing import Dict, List, Optional

from app.core.unified_api_client import get_unified_api_client, APIProvider
from app.processors.data_transformation_pipeline import get_transformation_pipeline
from app.core.database_manager_extension import get_extended_database_manager
from app.core.multi_api_key_manager import get_api_key_manager
from app.core.concurrent_api_manager import (
    get_concurrent_api_manager,
    APICallTask,
    APICallPriority,
    ConcurrencyConfig
)
from app.core.selective_storage_manager import get_storage_manager
from app.archiving.archival_engine import get_archival_engine
from app.archiving.backup_manager import get_backup_manager


class UnifiedKTOClient:
    """í†µí•© KTO API í´ë¼ì´ì–¸íŠ¸"""

    def __init__(self, enable_parallel: bool = True, concurrency_config: ConcurrencyConfig = None):
        self.logger = logging.getLogger(__name__)
        self.api_client = get_unified_api_client()
        self.transformation_pipeline = get_transformation_pipeline()
        self.db_manager = get_extended_database_manager()
        self.key_manager = get_api_key_manager()
        self.storage_manager = get_storage_manager()

        # ì•„ì¹´ì´ë¹™ ì‹œìŠ¤í…œ
        self.archival_engine = get_archival_engine()
        self.backup_manager = get_backup_manager()

        # ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •
        self.enable_parallel = enable_parallel
        if enable_parallel:
            self.concurrent_manager = get_concurrent_api_manager(concurrency_config)
        else:
            self.concurrent_manager = None

        # ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì„¤ì •
        self.default_params = {
            "MobileOS": "ETC",
            "MobileApp": "WeatherFlick",
            "_type": "json",
        }

        # ì»¨í…ì¸  íƒ€ì… ì •ì˜
        self.content_types = {
            "12": "tourist_attractions",  # ê´€ê´‘ì§€
            "14": "cultural_facilities",  # ë¬¸í™”ì‹œì„¤
            "15": "festivals_events",  # ì¶•ì œê³µì—°í–‰ì‚¬
            "25": "travel_courses",  # ì—¬í–‰ì½”ìŠ¤
            "28": "leisure_sports",  # ë ˆí¬ì¸ 
            "32": "accommodations",  # ìˆ™ë°•
            "38": "shopping",  # ì‡¼í•‘
            "39": "restaurants",  # ìŒì‹ì 
        }

        # ì§€ì—­ ì½”ë“œ (ì „êµ­ ì£¼ìš” ì§€ì—­)
        self.area_codes = [
            "1",  # ì„œìš¸
            "2",  # ì¸ì²œ
            "3",  # ëŒ€ì „
            "4",  # ëŒ€êµ¬
            "5",  # ê´‘ì£¼
            "6",  # ë¶€ì‚°
            "7",  # ìš¸ì‚°
            "8",  # ì„¸ì¢…
            "31",  # ê²½ê¸°
            "32",  # ê°•ì›
            "33",  # ì¶©ë¶
            "34",  # ì¶©ë‚¨
            "35",  # ê²½ë¶
            "36",  # ê²½ë‚¨
            "37",  # ì „ë¶
            "38",  # ì „ë‚¨
            "39",  # ì œì£¼
        ]

    async def collect_all_data(
        self,
        content_types: Optional[List[str]] = None,
        area_codes: Optional[List[str]] = None,
        store_raw: bool = True,
        auto_transform: bool = True,
        include_new_apis: bool = True,
        include_hierarchical_regions: bool = False,
        use_priority_sorting: bool = False,
    ) -> Dict:
        """
        ëª¨ë“  KTO ë°ì´í„° ìˆ˜ì§‘ (ì‹ ê·œ API í¬í•¨)

        Args:
            content_types: ìˆ˜ì§‘í•  ì»¨í…ì¸  íƒ€ì… ëª©ë¡ (Noneì´ë©´ ì „ì²´)
            area_codes: ìˆ˜ì§‘í•  ì§€ì—­ ì½”ë“œ ëª©ë¡ (Noneì´ë©´ ì „ì²´)
            store_raw: ì›ë³¸ ë°ì´í„° ì €ì¥ ì—¬ë¶€
            auto_transform: ìë™ ë³€í™˜ ìˆ˜í–‰ ì—¬ë¶€
            include_new_apis: ì‹ ê·œ ì¶”ê°€ëœ 4ê°œ API í¬í•¨ ì—¬ë¶€
            include_hierarchical_regions: ê³„ì¸µì  ì§€ì—­ì½”ë“œ ìˆ˜ì§‘ í¬í•¨ ì—¬ë¶€
            use_priority_sorting: ë°ì´í„° ë¶€ì¡± ìˆœìœ¼ë¡œ ìš°ì„ ìˆœìœ„ ì •ë ¬ ì—¬ë¶€

        Returns:
            Dict: ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½
        """

        if content_types is None:
            content_types = list(self.content_types.keys())

        # ìš°ì„ ìˆœìœ„ ì •ë ¬ ì‚¬ìš© ì‹œ ë°ì´í„° ë¶€ì¡± ìˆœìœ¼ë¡œ ì •ë ¬
        if use_priority_sorting:
            from app.core.data_priority_manager import get_priority_manager
            priority_manager = get_priority_manager()

            # ì»¨í…ì¸  íƒ€ì…ì„ ë°ì´í„° ë¶€ì¡± ìˆœìœ¼ë¡œ ì •ë ¬
            priority_list = priority_manager.get_priority_sorted_content_types(content_types)
            content_types = [item[0] for item in priority_list]  # ìš°ì„ ìˆœìœ„ ìˆœì„œë¡œ ì¬ì •ë ¬

            self.logger.info(f"ğŸ¯ ìš°ì„ ìˆœìœ„ ì •ë ¬ í™œì„±í™”: {len(content_types)}ê°œ ì»¨í…ì¸  íƒ€ì…")
            for rank, (content_type, count, name) in enumerate(priority_list, 1):
                urgency = "ğŸ”¥" if count == 0 else "âš ï¸" if count < 1000 else "âœ…"
                self.logger.info(f"  {rank}. {name} (íƒ€ì… {content_type}): {count:,}ê°œ {urgency}")

        if area_codes is None:
            area_codes = self.area_codes

        # API ì œí•œ ìƒíƒœ í™•ì¸ - ëª¨ë“  KTO API í‚¤ê°€ ì œí•œë˜ì—ˆëŠ”ì§€ í™•ì¸
        # ëª¨ë“  í‚¤ê°€ ì œí•œëœ ê²½ìš° ì‘ì—…ì„ ê±´ë„ˆë›°ê³  ë‹¤ìŒ ë°°ì¹˜ ì‹¤í–‰ ì‹œê°„ê¹Œì§€ ëŒ€ê¸°
        if self.key_manager.are_all_keys_rate_limited(APIProvider.KTO):
            next_reset_time = self.key_manager.get_next_reset_time(APIProvider.KTO)
            rate_limit_status = self.key_manager.get_rate_limit_status(APIProvider.KTO)

            error_msg = (
                f"ëª¨ë“  KTO API í‚¤ê°€ ì œí•œë˜ì–´ ìˆìŠµë‹ˆë‹¤. "
                f"í™œì„± í‚¤: {rate_limit_status['active_keys']}/{rate_limit_status['total_keys']}, "
                f"ì œí•œëœ í‚¤: {rate_limit_status['limited_keys']}ê°œ"
            )

            if next_reset_time:
                time_until_reset = next_reset_time - datetime.now()
                hours = int(time_until_reset.total_seconds() // 3600)
                minutes = int((time_until_reset.total_seconds() % 3600) // 60)
                error_msg += f" ë‹¤ìŒ ì¬ì‹œë„ ê°€ëŠ¥ ì‹œê°„: {next_reset_time.strftime('%Y-%m-%d %H:%M:%S')} (ì•½ {hours}ì‹œê°„ {minutes}ë¶„ í›„)"

            self.logger.warning(error_msg)

            return {
                "sync_batch_id": f"kto_sync_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "started_at": datetime.utcnow().isoformat(),
                "completed_at": datetime.utcnow().isoformat(),
                "status": "skipped",
                "reason": "all_api_keys_rate_limited",
                "next_retry_time": next_reset_time.isoformat() if next_reset_time else None,
                "rate_limit_status": rate_limit_status,
                "content_types_collected": {},
                "new_apis_collected": {},
                "total_raw_records": 0,
                "total_processed_records": 0,
                "errors": [error_msg],
            }

        sync_batch_id = f"kto_sync_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        collection_results = {
            "sync_batch_id": sync_batch_id,
            "started_at": datetime.utcnow().isoformat(),
            "status": "running",
            "content_types_collected": {},
            "new_apis_collected": {},
            "total_raw_records": 0,
            "total_processed_records": 0,
            "errors": [],
        }

        self.logger.info(f"KTO ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {sync_batch_id}")

        async with self.api_client:

            for content_type in content_types:
                content_name = self.content_types.get(
                    content_type, f"unknown_{content_type}"
                )

                self.logger.info(f"ìˆ˜ì§‘ ì‹œì‘: {content_name} (íƒ€ì…: {content_type})")

                content_results = {
                    "content_type": content_type,
                    "content_name": content_name,
                    "areas": {},
                    "total_raw_records": 0,
                    "total_processed_records": 0,
                    "errors": [],
                }

                for area_code in area_codes:
                    try:
                        area_result = await self._collect_area_data(
                            content_type,
                            area_code,
                            sync_batch_id,
                            store_raw,
                            auto_transform,
                        )

                        content_results["areas"][area_code] = area_result
                        content_results["total_raw_records"] += area_result.get(
                            "raw_records", 0
                        )
                        content_results["total_processed_records"] += area_result.get(
                            "processed_records", 0
                        )

                        # API í˜¸ì¶œ ê°„ê²© ì¡°ì •
                        await asyncio.sleep(0.5)

                    except Exception as e:
                        error_msg = f"ì§€ì—­ {area_code} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}"
                        self.logger.error(error_msg)
                        content_results["errors"].append(error_msg)

                collection_results["content_types_collected"][
                    content_type
                ] = content_results
                collection_results["total_raw_records"] += content_results[
                    "total_raw_records"
                ]
                collection_results["total_processed_records"] += content_results[
                    "total_processed_records"
                ]

                self.logger.info(
                    f"ìˆ˜ì§‘ ì™„ë£Œ: {content_name} - ì›ë³¸ {content_results['total_raw_records']}ê±´, ì²˜ë¦¬ {content_results['total_processed_records']}ê±´"
                )

            # ì‹ ê·œ API ìˆ˜ì§‘ (ì‚¬ìš©ìê°€ ìš”ì²­í•œ ê²½ìš°)
            if include_new_apis:
                self.logger.info("=== ì‹ ê·œ API ìˆ˜ì§‘ ì‹œì‘ ===")

                # 1. ë°˜ë ¤ë™ë¬¼ ë™ë°˜ì—¬í–‰ ì •ë³´ ìˆ˜ì§‘
                try:
                    pet_tour_result = await self.collect_pet_tour_data(
                        content_ids=None,  # ì „ì²´ ì¡°íšŒ
                        store_raw=store_raw,
                        auto_transform=auto_transform
                    )
                    collection_results["new_apis_collected"]["pet_tour"] = pet_tour_result
                    collection_results["total_raw_records"] += pet_tour_result.get("total_raw_records", 0)
                    collection_results["total_processed_records"] += pet_tour_result.get("total_processed_records", 0)

                    self.logger.info(f"ë°˜ë ¤ë™ë¬¼ ë™ë°˜ì—¬í–‰ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ: ì›ë³¸ {pet_tour_result.get('total_raw_records', 0)}ê±´")

                except Exception as e:
                    error_msg = f"ë°˜ë ¤ë™ë¬¼ ë™ë°˜ì—¬í–‰ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}"
                    self.logger.error(error_msg)
                    collection_results["errors"].append(error_msg)

                # 2. ë¶„ë¥˜ì²´ê³„ ì½”ë“œ ìˆ˜ì§‘
                try:
                    classification_result = await self.collect_classification_system_codes(
                        store_raw=store_raw,
                        auto_transform=auto_transform
                    )
                    collection_results["new_apis_collected"]["classification_codes"] = classification_result
                    collection_results["total_raw_records"] += classification_result.get("total_raw_records", 0)
                    collection_results["total_processed_records"] += classification_result.get("total_processed_records", 0)

                    self.logger.info(f"ë¶„ë¥˜ì²´ê³„ ì½”ë“œ ìˆ˜ì§‘ ì™„ë£Œ: ì›ë³¸ {classification_result.get('total_raw_records', 0)}ê±´")

                except Exception as e:
                    error_msg = f"ë¶„ë¥˜ì²´ê³„ ì½”ë“œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}"
                    self.logger.error(error_msg)
                    collection_results["errors"].append(error_msg)

                # 3. ì§€ì—­ ê¸°ë°˜ ë™ê¸°í™” ëª©ë¡ ìˆ˜ì§‘ (ì£¼ìš” ì§€ì—­ë§Œ)
                try:
                    sync_list_result = await self.collect_area_based_sync_list(
                        content_type_id="12",
                        area_code="1",  # ì„œìš¸
                        modified_time=None,
                        store_raw=store_raw,
                        auto_transform=auto_transform
                    )
                    collection_results["new_apis_collected"]["sync_list"] = sync_list_result
                    collection_results["total_raw_records"] += sync_list_result.get("total_raw_records", 0)
                    collection_results["total_processed_records"] += sync_list_result.get("total_processed_records", 0)

                    self.logger.info(f"ì§€ì—­ ê¸°ë°˜ ë™ê¸°í™” ëª©ë¡ ìˆ˜ì§‘ ì™„ë£Œ: ì›ë³¸ {sync_list_result.get('total_raw_records', 0)}ê±´")

                except Exception as e:
                    error_msg = f"ì§€ì—­ ê¸°ë°˜ ë™ê¸°í™” ëª©ë¡ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}"
                    self.logger.error(error_msg)
                    collection_results["errors"].append(error_msg)

                # 4. ë²•ì •ë™ ì½”ë“œ ìˆ˜ì§‘ (ì£¼ìš” ì§€ì—­ë§Œ)
                try:
                    legal_dong_result = await self.collect_legal_dong_codes(
                        area_code="1",  # ì„œìš¸
                        store_raw=store_raw,
                        auto_transform=auto_transform
                    )
                    collection_results["new_apis_collected"]["legal_dong_codes"] = legal_dong_result
                    collection_results["total_raw_records"] += legal_dong_result.get("total_raw_records", 0)
                    collection_results["total_processed_records"] += legal_dong_result.get("total_processed_records", 0)

                    self.logger.info(f"ë²•ì •ë™ ì½”ë“œ ìˆ˜ì§‘ ì™„ë£Œ: ì›ë³¸ {legal_dong_result.get('total_raw_records', 0)}ê±´")

                except Exception as e:
                    error_msg = f"ë²•ì •ë™ ì½”ë“œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}"
                    self.logger.error(error_msg)
                    collection_results["errors"].append(error_msg)

            # ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ (detailCommon2, detailIntro2, detailInfo2, detailImage2)
            if include_new_apis:
                self.logger.info("=== ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘ ===")

                try:
                    detail_collection_result = await self.collect_detailed_information(
                        content_types=content_types or list(self.content_types.keys()),
                        max_content_ids=50,  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì œí•œ
                        store_raw=store_raw,
                        auto_transform=auto_transform
                    )
                    collection_results["new_apis_collected"]["detailed_info"] = detail_collection_result
                    collection_results["total_raw_records"] += detail_collection_result.get("total_raw_records", 0)
                    collection_results["total_processed_records"] += detail_collection_result.get("total_processed_records", 0)

                    self.logger.info(f"ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ: ì›ë³¸ {detail_collection_result.get('total_raw_records', 0)}ê±´")

                except Exception as e:
                    error_msg = f"ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}"
                    self.logger.error(error_msg)
                    collection_results["errors"].append(error_msg)

                self.logger.info("=== ì‹ ê·œ API ìˆ˜ì§‘ ì™„ë£Œ ===")

            # 5. ê³„ì¸µì  ì§€ì—­ì½”ë“œ ìˆ˜ì§‘ (ì˜µì…˜)
            if include_hierarchical_regions:
                self.logger.info("=== ê³„ì¸µì  ì§€ì—­ì½”ë“œ ìˆ˜ì§‘ ì‹œì‘ ===")
                try:
                    hierarchical_result = await self.collect_hierarchical_area_codes(
                        force_update=False,
                        store_raw=store_raw
                    )
                    collection_results["hierarchical_regions_collected"] = hierarchical_result

                    # ìˆ˜ì§‘ í†µê³„ì— ì¶”ê°€
                    provinces_count = hierarchical_result.get("total_provinces", 0)
                    districts_count = hierarchical_result.get("total_districts", 0)
                    collection_results["total_raw_records"] += provinces_count + districts_count

                    self.logger.info(f"ê³„ì¸µì  ì§€ì—­ì½”ë“œ ìˆ˜ì§‘ ì™„ë£Œ: ì‹œë„ {provinces_count}ê°œ, ì‹œêµ°êµ¬ {districts_count}ê°œ")

                except Exception as e:
                    error_msg = f"ê³„ì¸µì  ì§€ì—­ì½”ë“œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}"
                    self.logger.error(error_msg)
                    collection_results["errors"].append(error_msg)

                self.logger.info("=== ê³„ì¸µì  ì§€ì—­ì½”ë“œ ìˆ˜ì§‘ ì™„ë£Œ ===")

        collection_results["completed_at"] = datetime.utcnow().isoformat()
        collection_results["status"] = "completed"

        self.logger.info(
            f"KTO ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {sync_batch_id} - ì´ ì›ë³¸ {collection_results['total_raw_records']}ê±´, ì²˜ë¦¬ {collection_results['total_processed_records']}ê±´"
        )

        return collection_results

    async def collect_pet_tour_data(
        self,
        content_ids: Optional[List[str]] = None,
        store_raw: bool = True,
        auto_transform: bool = True
    ) -> Dict:
        """
        ë°˜ë ¤ë™ë¬¼ ë™ë°˜ì—¬í–‰ ì •ë³´ ìˆ˜ì§‘ (detailPetTour2)

        Args:
            content_ids: ìˆ˜ì§‘í•  ì½˜í…ì¸  ID ëª©ë¡ (Noneì´ë©´ ì „ì²´ ì¡°íšŒ)
            store_raw: ì›ë³¸ ë°ì´í„° ì €ì¥ ì—¬ë¶€
            auto_transform: ìë™ ë³€í™˜ ìˆ˜í–‰ ì—¬ë¶€

        Returns:
            Dict: ìˆ˜ì§‘ ê²°ê³¼
        """

        sync_batch_id = f"pet_tour_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.logger.info(f"ë°˜ë ¤ë™ë¬¼ ë™ë°˜ì—¬í–‰ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘: {sync_batch_id}")

        collection_results = {
            "sync_batch_id": sync_batch_id,
            "api_endpoint": "detailPetTour2",
            "started_at": datetime.utcnow().isoformat(),
            "total_raw_records": 0,
            "total_processed_records": 0,
            "errors": []
        }

        async with self.api_client:
            try:
                params = {
                    **self.default_params,
                    "numOfRows": 100,
                    "pageNo": 1
                }

                if content_ids:
                    # íŠ¹ì • contentIdë“¤ ì²˜ë¦¬
                    for content_id in content_ids:
                        params["contentId"] = content_id

                        response = await self.api_client.call_api(
                            api_provider=APIProvider.KTO,
                            endpoint="detailPetTour2",
                            params=params,
                            store_raw=store_raw
                        )

                        if response.success and response.data:
                            items = response.data.get("items", {})
                            if items and "item" in items:
                                item_list = items["item"]
                                if isinstance(item_list, dict):
                                    item_list = [item_list]

                                collection_results["total_raw_records"] += len(item_list)

                                if auto_transform and response.raw_data_id:
                                    # ì‹¤ì œ ë°ì´í„° ë³€í™˜ ë° ì €ì¥
                                    processed_count = await self._transform_and_save_pet_tour_data(
                                        response.raw_data_id, item_list
                                    )
                                    collection_results["total_processed_records"] += processed_count

                        await asyncio.sleep(0.3)
                else:
                    # ì „ì²´ ì¡°íšŒ
                    response = await self.api_client.call_api(
                        api_provider=APIProvider.KTO,
                        endpoint="detailPetTour2",
                        params=params,
                        store_raw=store_raw
                    )

                    if response.success and response.data:
                        items = response.data.get("items", {})
                        if items and "item" in items:
                            item_list = items["item"]
                            if isinstance(item_list, dict):
                                item_list = [item_list]

                            collection_results["total_raw_records"] = len(item_list)

                            if auto_transform and response.raw_data_id:
                                # ì‹¤ì œ ë°ì´í„° ë³€í™˜ ë° ì €ì¥
                                processed_count = await self._transform_and_save_pet_tour_data(
                                    response.raw_data_id, item_list
                                )
                                collection_results["total_processed_records"] = processed_count

            except Exception as e:
                error_msg = f"í«íˆ¬ì–´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}"
                self.logger.error(error_msg)
                collection_results["errors"].append(error_msg)

        collection_results["completed_at"] = datetime.utcnow().isoformat()

        self.logger.info(
            f"ë°˜ë ¤ë™ë¬¼ ë™ë°˜ì—¬í–‰ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ: {sync_batch_id} - ì´ ì›ë³¸ {collection_results['total_raw_records']}ê±´, ì²˜ë¦¬ {collection_results['total_processed_records']}ê±´"
        )

        return collection_results

    async def _transform_and_save_pet_tour_data(self, raw_data_id: str, item_list: List[Dict]) -> int:
        """ë°˜ë ¤ë™ë¬¼ ë™ë°˜ì—¬í–‰ ë°ì´í„° ë³€í™˜ ë° ì €ì¥"""
        try:
            # ë°ì´í„° ë³€í™˜
            transformation_result = await self.transformation_pipeline.transform_raw_data(raw_data_id)

            if not transformation_result.success or not transformation_result.processed_data:
                self.logger.warning(f"ë°˜ë ¤ë™ë¬¼ ë™ë°˜ì—¬í–‰ ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨: {raw_data_id}")
                return 0

            # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
            saved_count = 0
            for processed_item in transformation_result.processed_data:
                # í•„ìˆ˜ ë©”íƒ€ë°ì´í„° ì¶”ê°€
                processed_item["raw_data_id"] = raw_data_id
                processed_item["data_quality_score"] = transformation_result.quality_score or 0.0
                processed_item["processing_status"] = "processed"
                processed_item["last_sync_at"] = datetime.utcnow()

                # pet_tour_info í…Œì´ë¸”ì— ì €ì¥
                if self.db_manager.upsert_pet_tour_info(processed_item):
                    saved_count += 1
                    self.logger.debug(f"ë°˜ë ¤ë™ë¬¼ ë™ë°˜ì—¬í–‰ ì •ë³´ ì €ì¥ ì„±ê³µ: {processed_item.get('title')}")
                else:
                    self.logger.warning(f"ë°˜ë ¤ë™ë¬¼ ë™ë°˜ì—¬í–‰ ì •ë³´ ì €ì¥ ì‹¤íŒ¨: {processed_item.get('title')}")

            self.logger.info(f"ë°˜ë ¤ë™ë¬¼ ë™ë°˜ì—¬í–‰ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ: {saved_count}/{len(transformation_result.processed_data)}ê±´ ì €ì¥")
            return saved_count

        except Exception as e:
            self.logger.error(f"ë°˜ë ¤ë™ë¬¼ ë™ë°˜ì—¬í–‰ ë°ì´í„° ë³€í™˜/ì €ì¥ ì‹¤íŒ¨: {e}")
            return 0

    async def collect_classification_system_codes(
        self,
        store_raw: bool = True,
        auto_transform: bool = True
    ) -> Dict:
        """
        ë¶„ë¥˜ì²´ê³„ ì½”ë“œ ì¡°íšŒ (lclsSystmCode2)

        Args:
            store_raw: ì›ë³¸ ë°ì´í„° ì €ì¥ ì—¬ë¶€
            auto_transform: ìë™ ë³€í™˜ ìˆ˜í–‰ ì—¬ë¶€

        Returns:
            Dict: ìˆ˜ì§‘ ê²°ê³¼
        """

        sync_batch_id = f"classification_codes_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.logger.info(f"ë¶„ë¥˜ì²´ê³„ ì½”ë“œ ìˆ˜ì§‘ ì‹œì‘: {sync_batch_id}")

        collection_results = {
            "sync_batch_id": sync_batch_id,
            "api_endpoint": "lclsSystmCode2",
            "started_at": datetime.utcnow().isoformat(),
            "total_raw_records": 0,
            "total_processed_records": 0,
            "errors": []
        }

        async with self.api_client:
            try:
                params = {
                    **self.default_params,
                    "numOfRows": 1000,
                    "pageNo": 1
                }

                response = await self.api_client.call_api(
                    api_provider=APIProvider.KTO,
                    endpoint="lclsSystmCode2",
                    params=params,
                    store_raw=store_raw
                )

                if response.success and response.data:
                    items = response.data.get("items", {})
                    if items and "item" in items:
                        item_list = items["item"]
                        if isinstance(item_list, dict):
                            item_list = [item_list]

                        collection_results["total_raw_records"] = len(item_list)

                        if auto_transform:
                            # ê°„ë‹¨í•œ ë°ì´í„° ì²˜ë¦¬ (ì‹¤ì œ transform ìƒëµ)
                            collection_results["total_processed_records"] = len(item_list)

            except Exception as e:
                error_msg = f"ë¶„ë¥˜ì²´ê³„ ì½”ë“œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}"
                self.logger.error(error_msg)
                collection_results["errors"].append(error_msg)

        collection_results["completed_at"] = datetime.utcnow().isoformat()

        self.logger.info(
            f"ë¶„ë¥˜ì²´ê³„ ì½”ë“œ ìˆ˜ì§‘ ì™„ë£Œ: {sync_batch_id} - ì´ ì›ë³¸ {collection_results['total_raw_records']}ê±´, ì²˜ë¦¬ {collection_results['total_processed_records']}ê±´"
        )

        return collection_results

    async def collect_area_based_sync_list(
        self,
        content_type_id: str = "12",
        area_code: str = "1",
        modified_time: str = None,
        store_raw: bool = True,
        auto_transform: bool = True
    ) -> Dict:
        """
        ì§€ì—­ê¸°ë°˜ ë™ê¸°í™” ëª©ë¡ ì¡°íšŒ (areaBasedSyncList2)

        Args:
            content_type_id: ì½˜í…ì¸  íƒ€ì… ID
            area_code: ì§€ì—­ ì½”ë“œ
            modified_time: ìˆ˜ì • ì‹œê°„ (YYYYMMDD í˜•ì‹)
            store_raw: ì›ë³¸ ë°ì´í„° ì €ì¥ ì—¬ë¶€
            auto_transform: ìë™ ë³€í™˜ ìˆ˜í–‰ ì—¬ë¶€

        Returns:
            Dict: ìˆ˜ì§‘ ê²°ê³¼
        """

        sync_batch_id = f"sync_list_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.logger.info(f"ì§€ì—­ê¸°ë°˜ ë™ê¸°í™” ëª©ë¡ ìˆ˜ì§‘ ì‹œì‘: {sync_batch_id}")

        collection_results = {
            "sync_batch_id": sync_batch_id,
            "api_endpoint": "areaBasedSyncList2",
            "started_at": datetime.utcnow().isoformat(),
            "total_raw_records": 0,
            "total_processed_records": 0,
            "content_types_collected": {},
            "errors": []
        }

        async with self.api_client:
            # ëª¨ë“  ì½˜í…ì¸  íƒ€ì…ì— ëŒ€í•´ ë™ê¸°í™” ëª©ë¡ ìˆ˜ì§‘
            for content_type in self.content_types.keys():
                try:
                    content_result = await self._collect_sync_list_by_content_type(
                        content_type, area_code, modified_time, sync_batch_id, store_raw, auto_transform
                    )

                    collection_results["content_types_collected"][content_type] = content_result
                    collection_results["total_raw_records"] += content_result.get("raw_records", 0)
                    collection_results["total_processed_records"] += content_result.get("processed_records", 0)

                    # API í˜¸ì¶œ ê°„ê²© ì¡°ì •
                    await asyncio.sleep(0.5)

                except Exception as e:
                    error_msg = f"ì½˜í…ì¸  íƒ€ì… {content_type} ë™ê¸°í™” ëª©ë¡ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}"
                    self.logger.error(error_msg)
                    collection_results["errors"].append(error_msg)

        collection_results["completed_at"] = datetime.utcnow().isoformat()

        self.logger.info(
            f"ì§€ì—­ê¸°ë°˜ ë™ê¸°í™” ëª©ë¡ ìˆ˜ì§‘ ì™„ë£Œ: {sync_batch_id} - ì´ ì›ë³¸ {collection_results['total_raw_records']}ê±´, ì²˜ë¦¬ {collection_results['total_processed_records']}ê±´"
        )

        return collection_results

    async def collect_legal_dong_codes(
        self,
        area_code: str = "1",
        store_raw: bool = True,
        auto_transform: bool = True
    ) -> Dict:
        """
        ë²•ì •ë™ ì½”ë“œ ì¡°íšŒ (ldongCode2)

        Args:
            area_code: ì§€ì—­ ì½”ë“œ
            store_raw: ì›ë³¸ ë°ì´í„° ì €ì¥ ì—¬ë¶€
            auto_transform: ìë™ ë³€í™˜ ìˆ˜í–‰ ì—¬ë¶€

        Returns:
            Dict: ìˆ˜ì§‘ ê²°ê³¼
        """

        sync_batch_id = f"legal_dong_codes_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.logger.info(f"ë²•ì •ë™ ì½”ë“œ ìˆ˜ì§‘ ì‹œì‘: {sync_batch_id}")

        collection_results = {
            "sync_batch_id": sync_batch_id,
            "api_endpoint": "ldongCode2",
            "started_at": datetime.utcnow().isoformat(),
            "total_raw_records": 0,
            "total_processed_records": 0,
            "areas_collected": {},
            "errors": []
        }

        async with self.api_client:
            for area_code in self.area_codes:
                try:
                    area_result = await self._collect_legal_dong_area_data(
                        area_code, sync_batch_id, store_raw, auto_transform
                    )

                    collection_results["areas_collected"][area_code] = area_result
                    collection_results["total_raw_records"] += area_result.get("raw_records", 0)
                    collection_results["total_processed_records"] += area_result.get("processed_records", 0)

                    # API í˜¸ì¶œ ê°„ê²© ì¡°ì •
                    await asyncio.sleep(0.5)

                except Exception as e:
                    error_msg = f"ì§€ì—­ {area_code} ë²•ì •ë™ ì½”ë“œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}"
                    self.logger.error(error_msg)
                    collection_results["errors"].append(error_msg)

        collection_results["completed_at"] = datetime.utcnow().isoformat()

        self.logger.info(
            f"ë²•ì •ë™ ì½”ë“œ ìˆ˜ì§‘ ì™„ë£Œ: {sync_batch_id} - ì´ ì›ë³¸ {collection_results['total_raw_records']}ê±´, ì²˜ë¦¬ {collection_results['total_processed_records']}ê±´"
        )

        return collection_results

    async def collect_hierarchical_area_codes(
        self,
        force_update: bool = False,
        store_raw: bool = True
    ) -> Dict:
        """
        ê³„ì¸µì  ì§€ì—­ì½”ë“œ ì™„ì „ ìˆ˜ì§‘ (ì‹œë„ + ì‹œêµ°êµ¬)

        Args:
            force_update: ê¸°ì¡´ ë°ì´í„° ë¬´ì‹œí•˜ê³  ê°•ì œ ì—…ë°ì´íŠ¸
            store_raw: ì›ë³¸ ë°ì´í„° ì €ì¥ ì—¬ë¶€

        Returns:
            Dict: ìˆ˜ì§‘ ê²°ê³¼
        """
        sync_batch_id = f"area_codes_hierarchical_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        collection_results = {
            "sync_batch_id": sync_batch_id,
            "started_at": datetime.utcnow().isoformat(),
            "provinces_collected": {},  # ì‹œë„ ë°ì´í„°
            "districts_collected": {},  # ì‹œêµ°êµ¬ ë°ì´í„°
            "total_provinces": 0,
            "total_districts": 0,
            "errors": []
        }

        self.logger.info(f"ê³„ì¸µì  ì§€ì—­ì½”ë“œ ìˆ˜ì§‘ ì‹œì‘: {sync_batch_id}")

        async with self.api_client:
            try:
                # 1ë‹¨ê³„: ì „ì²´ ì‹œë„ ì½”ë“œ ìˆ˜ì§‘
                self.logger.info("1ë‹¨ê³„: ì‹œë„ ì½”ë“œ ìˆ˜ì§‘")
                provinces_result = await self._collect_province_codes(sync_batch_id, store_raw)
                collection_results["provinces_collected"] = provinces_result
                collection_results["total_provinces"] = provinces_result.get("total_records", 0)

                # 2ë‹¨ê³„: ê° ì‹œë„ë³„ ì‹œêµ°êµ¬ ì½”ë“œ ìˆ˜ì§‘
                self.logger.info("2ë‹¨ê³„: ì‹œêµ°êµ¬ ì½”ë“œ ìˆ˜ì§‘")
                province_codes = provinces_result.get("province_codes", [])

                for province_code in province_codes:
                    try:
                        district_result = await self._collect_district_codes(
                            province_code, sync_batch_id, store_raw
                        )
                        collection_results["districts_collected"][province_code] = district_result
                        collection_results["total_districts"] += district_result.get("total_records", 0)

                        # API í˜¸ì¶œ ê°„ê²© ì¡°ì •
                        await asyncio.sleep(0.5)

                    except Exception as e:
                        error_msg = f"ì§€ì—­ {province_code} ì‹œêµ°êµ¬ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}"
                        self.logger.error(error_msg)
                        collection_results["errors"].append(error_msg)

                # 3ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ë° ì—…ë°ì´íŠ¸
                await self._save_hierarchical_region_data(collection_results)

            except Exception as e:
                error_msg = f"ê³„ì¸µì  ì§€ì—­ì½”ë“œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}"
                self.logger.error(error_msg)
                collection_results["errors"].append(error_msg)

        collection_results["completed_at"] = datetime.utcnow().isoformat()

        self.logger.info(
            f"ê³„ì¸µì  ì§€ì—­ì½”ë“œ ìˆ˜ì§‘ ì™„ë£Œ: ì‹œë„ {collection_results['total_provinces']}ê°œ, "
            f"ì‹œêµ°êµ¬ {collection_results['total_districts']}ê°œ"
        )

        return collection_results

    async def _collect_province_codes(self, sync_batch_id: str, store_raw: bool) -> Dict:
        """ì‹œë„ ì½”ë“œ ìˆ˜ì§‘"""
        result = {
            "total_records": 0,
            "province_codes": [],
            "raw_data_ids": [],
            "errors": []
        }

        try:
            params = {
                **self.default_params,
                "numOfRows": 20  # ì‹œë„ëŠ” 17ê°œì´ë¯€ë¡œ ì¶©ë¶„
            }

            response = await self.api_client.call_api(
                api_provider=APIProvider.KTO,
                endpoint="areaCode2",
                params=params,
                store_raw=store_raw
            )

            if response.success and response.data:
                items = response.data.get("items", {}).get("item", [])
                if not isinstance(items, list):
                    items = [items]

                result["total_records"] = len(items)
                result["province_codes"] = [item.get("code") for item in items]

                if response.raw_data_id:
                    result["raw_data_ids"].append(response.raw_data_id)

                self.logger.info(f"ì‹œë„ ì½”ë“œ {len(items)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")

        except Exception as e:
            error_msg = f"ì‹œë„ ì½”ë“œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}"
            result["errors"].append(error_msg)
            self.logger.error(error_msg)

        return result

    async def _collect_district_codes(self, province_code: str, sync_batch_id: str, store_raw: bool) -> Dict:
        """íŠ¹ì • ì‹œë„ì˜ ì‹œêµ°êµ¬ ì½”ë“œ ìˆ˜ì§‘"""
        result = {
            "province_code": province_code,
            "total_records": 0,
            "district_codes": [],
            "raw_data_ids": [],
            "errors": []
        }

        try:
            params = {
                **self.default_params,
                "areaCode": province_code,
                "numOfRows": 50  # ê²½ê¸°ë„ê°€ 31ê°œë¡œ ê°€ì¥ ë§ìŒ
            }

            response = await self.api_client.call_api(
                api_provider=APIProvider.KTO,
                endpoint="areaCode2",
                params=params,
                store_raw=store_raw
            )

            if response.success and response.data:
                items = response.data.get("items", {}).get("item", [])
                if not isinstance(items, list):
                    items = [items]

                result["total_records"] = len(items)
                result["district_codes"] = [
                    {"code": item.get("code"), "name": item.get("name")}
                    for item in items
                ]

                if response.raw_data_id:
                    result["raw_data_ids"].append(response.raw_data_id)

                self.logger.info(f"ì§€ì—­ {province_code} ì‹œêµ°êµ¬ {len(items)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")

        except Exception as e:
            error_msg = f"ì§€ì—­ {province_code} ì‹œêµ°êµ¬ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}"
            result["errors"].append(error_msg)
            self.logger.error(error_msg)

        return result

    async def _save_hierarchical_region_data(self, collection_results: Dict):
        """ìˆ˜ì§‘ëœ ê³„ì¸µì  ì§€ì—­ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        try:
            provinces_data = collection_results.get("provinces_collected", {})
            districts_data = collection_results.get("districts_collected", {})

            saved_count = 0

            # 1. ì‹œë„ ë°ì´í„° ì €ì¥ (regions í…Œì´ë¸”ì— ì§ì ‘ ì €ì¥)
            if provinces_data.get("province_codes"):
                for province_code in provinces_data["province_codes"]:
                    try:
                        # ì‹œë„ëª… ë§¤í•‘
                        province_names = {
                            "1": "ì„œìš¸íŠ¹ë³„ì‹œ", "2": "ì¸ì²œê´‘ì—­ì‹œ", "3": "ëŒ€ì „ê´‘ì—­ì‹œ",
                            "4": "ëŒ€êµ¬ê´‘ì—­ì‹œ", "5": "ê´‘ì£¼ê´‘ì—­ì‹œ", "6": "ë¶€ì‚°ê´‘ì—­ì‹œ",
                            "7": "ìš¸ì‚°ê´‘ì—­ì‹œ", "8": "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ", "31": "ê²½ê¸°ë„",
                            "32": "ê°•ì›íŠ¹ë³„ìì¹˜ë„", "33": "ì¶©ì²­ë¶ë„", "34": "ì¶©ì²­ë‚¨ë„",
                            "35": "ê²½ìƒë¶ë„", "36": "ê²½ìƒë‚¨ë„", "37": "ì „ë¶íŠ¹ë³„ìì¹˜ë„",
                            "38": "ì „ë¼ë‚¨ë„", "39": "ì œì£¼ë„"
                        }

                        province_name = province_names.get(province_code, f"ì§€ì—­{province_code}")

                        # regions í…Œì´ë¸”ì— UPSERT
                        upsert_query = """
                            INSERT INTO regions (region_code, region_name, parent_region_code, region_level, created_at, updated_at)
                            VALUES (%s, %s, %s, %s, NOW(), NOW())
                            ON CONFLICT (region_code)
                            DO UPDATE SET
                                region_name = EXCLUDED.region_name,
                                parent_region_code = EXCLUDED.parent_region_code,
                                region_level = EXCLUDED.region_level,
                                updated_at = NOW()
                        """

                        self.db_manager.execute_update(
                            upsert_query,
                            (province_code, province_name, None, 1)
                        )
                        saved_count += 1

                    except Exception as e:
                        self.logger.error(f"ì‹œë„ {province_code} ì €ì¥ ì‹¤íŒ¨: {e}")

            # 2. ì‹œêµ°êµ¬ ë°ì´í„° ì €ì¥
            for province_code, district_data in districts_data.items():
                district_codes = district_data.get("district_codes", [])

                for district in district_codes:
                    try:
                        district_code = district.get("code")
                        district_name = district.get("name")

                        if district_code and district_name:
                            # ì‹œêµ°êµ¬ ì½”ë“œëŠ” ì‹œë„ì½”ë“œ_ì‹œêµ°êµ¬ì½”ë“œ í˜•íƒœë¡œ ì €ì¥
                            full_district_code = f"{province_code}_{district_code}"

                            # regions í…Œì´ë¸”ì— UPSERT
                            upsert_query = """
                                INSERT INTO regions (region_code, region_name, parent_region_code, region_level, created_at, updated_at)
                                VALUES (%s, %s, %s, %s, NOW(), NOW())
                                ON CONFLICT (region_code)
                                DO UPDATE SET
                                    region_name = EXCLUDED.region_name,
                                    parent_region_code = EXCLUDED.parent_region_code,
                                    region_level = EXCLUDED.region_level,
                                    updated_at = NOW()
                            """

                            self.db_manager.execute_update(
                                upsert_query,
                                (full_district_code, district_name, province_code, 2)
                            )
                            saved_count += 1

                    except Exception as e:
                        self.logger.error(f"ì‹œêµ°êµ¬ {province_code}_{district.get('code', 'N/A')} ì €ì¥ ì‹¤íŒ¨: {e}")

            self.logger.info(f"ê³„ì¸µì  ì§€ì—­ ë°ì´í„° ì €ì¥ ì™„ë£Œ: ì´ {saved_count}ê°œ ì €ì¥")

        except Exception as e:
            self.logger.error(f"ê³„ì¸µì  ì§€ì—­ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")

    async def _collect_area_data(
        self,
        content_type: str,
        area_code: str,
        sync_batch_id: str,
        store_raw: bool,
        auto_transform: bool,
    ) -> Dict:
        """íŠ¹ì • ì§€ì—­ì˜ íŠ¹ì • íƒ€ì… ë°ì´í„° ìˆ˜ì§‘"""

        area_result = {
            "area_code": area_code,
            "content_type": content_type,
            "raw_records": 0,
            "processed_records": 0,
            "pages_collected": 0,
            "raw_data_ids": [],
            "errors": [],
        }

        page_no = 1
        num_of_rows = 100

        while True:
            try:
                # API í˜¸ì¶œ íŒŒë¼ë¯¸í„° êµ¬ì„±
                params = {
                    **self.default_params,
                    "contentTypeId": content_type,
                    "areaCode": area_code,
                    "pageNo": page_no,
                    "numOfRows": num_of_rows,
                }

                # API í˜¸ì¶œ
                response = await self.api_client.call_api(
                    api_provider=APIProvider.KTO,
                    endpoint="areaBasedList2",
                    params=params,
                    store_raw=store_raw,
                    cache_ttl=7200,  # 2ì‹œê°„ ìºì‹œ
                )

                if not response.success:
                    error_msg = f"API í˜¸ì¶œ ì‹¤íŒ¨: {response.error}"
                    area_result["errors"].append(error_msg)
                    break

                # ì‘ë‹µ ë°ì´í„° í™•ì¸
                response_body = response.data  # UnifiedAPIClientê°€ ì´ë¯¸ bodyë§Œ ë°˜í™˜
                total_count = response_body.get("totalCount", 0)
                items = response_body.get("items", {})

                if total_count == 0 or not items or "item" not in items:
                    # ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìŒ
                    break

                page_items = items["item"]
                if isinstance(page_items, dict):
                    page_items = [page_items]

                current_page_count = len(page_items)
                area_result["raw_records"] += current_page_count
                area_result["pages_collected"] += 1

                if response.raw_data_id:
                    area_result["raw_data_ids"].append(response.raw_data_id)

                # ìë™ ë³€í™˜ ìˆ˜í–‰
                if auto_transform and response.raw_data_id:
                    try:
                        transform_result = (
                            await self.transformation_pipeline.transform_raw_data(
                                response.raw_data_id
                            )
                        )

                        if transform_result.success:
                            # ë³€í™˜ëœ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                            saved_count = await self._save_processed_data(
                                content_type,
                                transform_result.processed_data,
                                response.raw_data_id,
                                transform_result.quality_score,
                            )
                            area_result["processed_records"] += saved_count

                    except Exception as e:
                        error_msg = f"ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨: {e}"
                        area_result["errors"].append(error_msg)

                # í˜ì´ì§€ë„¤ì´ì…˜ ì¡°ê±´ í™•ì¸
                if (
                    current_page_count < num_of_rows
                    or area_result["raw_records"] >= total_count
                ):
                    break

                page_no += 1

            except Exception as e:
                error_msg = f"í˜ì´ì§€ {page_no} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}"
                area_result["errors"].append(error_msg)
                break

        return area_result

    async def _collect_pet_tour_area_data(
        self,
        content_type_id: str,
        area_code: str,
        sync_batch_id: str,
        store_raw: bool,
        auto_transform: bool,
    ) -> Dict:
        """íŠ¹ì • ì§€ì—­ì˜ ë°˜ë ¤ë™ë¬¼ ë™ë°˜ì—¬í–‰ ì •ë³´ ìˆ˜ì§‘"""

        area_result = {
            "area_code": area_code,
            "content_type_id": content_type_id,
            "raw_records": 0,
            "processed_records": 0,
            "pages_collected": 0,
            "raw_data_ids": [],
            "errors": []
        }

        page_no = 1
        num_of_rows = 100

        while True:
            try:
                params = {
                    **self.default_params,
                    "contentTypeId": content_type_id,
                    "areaCode": area_code,
                    "numOfRows": num_of_rows,
                    "pageNo": page_no
                }

                response = await self.api_client.call_api(
                    api_provider=APIProvider.KTO,
                    endpoint="detailPetTour2",
                    params=params,
                    store_raw=store_raw
                )

                if response.success:
                    current_page_count = len(response.data.get("items", []))
                    area_result["raw_records"] += current_page_count
                    area_result["pages_collected"] += 1
                    area_result["raw_data_ids"].append(response.raw_data_id)

                    # ìë™ ë³€í™˜ ìˆ˜í–‰
                    if auto_transform and response.raw_data_id:
                        try:
                            transform_result = await self.transformation_pipeline.transform_raw_data(
                                response.raw_data_id
                            )

                            if transform_result.success:
                                # ë³€í™˜ëœ ë°ì´í„°ë¥¼ í«íˆ¬ì–´ í…Œì´ë¸”ì— ì €ì¥
                                saved_count = await self._save_pet_tour_data(
                                    transform_result.processed_data,
                                    sync_batch_id,
                                    response.raw_data_id
                                )
                                area_result["processed_records"] += saved_count

                        except Exception as e:
                            error_msg = f"í«íˆ¬ì–´ ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨: {e}"
                            area_result["errors"].append(error_msg)

                    # í˜ì´ì§€ë„¤ì´ì…˜ ì¢…ë£Œ ì¡°ê±´
                    if current_page_count < num_of_rows:
                        break
                else:
                    break

                page_no += 1

            except Exception as e:
                error_msg = f"í«íˆ¬ì–´ í˜ì´ì§€ {page_no} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}"
                area_result["errors"].append(error_msg)
                break

        return area_result

    async def _collect_sync_list_by_content_type(
        self,
        content_type_id: str,
        area_code: str,
        modified_time: str,
        sync_batch_id: str,
        store_raw: bool,
        auto_transform: bool,
    ) -> Dict:
        """ì½˜í…ì¸  íƒ€ì…ë³„ ë™ê¸°í™” ëª©ë¡ ìˆ˜ì§‘"""

        content_result = {
            "content_type_id": content_type_id,
            "area_code": area_code,
            "raw_records": 0,
            "processed_records": 0,
            "pages_collected": 0,
            "raw_data_ids": [],
            "errors": []
        }

        page_no = 1
        num_of_rows = 100

        while True:
            try:
                params = {
                    **self.default_params,
                    "contentTypeId": content_type_id,
                    "areaCode": area_code,
                    "numOfRows": num_of_rows,
                    "pageNo": page_no
                }

                # ìˆ˜ì • ì‹œê°„ì´ ì§€ì •ëœ ê²½ìš° ì¶”ê°€
                if modified_time:
                    params["modifiedtime"] = modified_time

                response = await self.api_client.call_api(
                    api_provider=APIProvider.KTO,
                    endpoint="areaBasedSyncList2",
                    params=params,
                    store_raw=store_raw
                )

                if response.success:
                    current_page_count = len(response.data.get("items", []))
                    content_result["raw_records"] += current_page_count
                    content_result["pages_collected"] += 1
                    content_result["raw_data_ids"].append(response.raw_data_id)

                    # ìë™ ë³€í™˜ ìˆ˜í–‰
                    if auto_transform and response.raw_data_id:
                        try:
                            transform_result = await self.transformation_pipeline.transform_raw_data(
                                response.raw_data_id
                            )

                            if transform_result.success:
                                # ë³€í™˜ëœ ë°ì´í„°ë¥¼ ë™ê¸°í™” ëª©ë¡ í…Œì´ë¸”ì— ì €ì¥
                                saved_count = await self._save_sync_list_data(
                                    transform_result.processed_data,
                                    sync_batch_id,
                                    response.raw_data_id
                                )
                                content_result["processed_records"] += saved_count

                        except Exception as e:
                            error_msg = f"ë™ê¸°í™” ëª©ë¡ ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨: {e}"
                            content_result["errors"].append(error_msg)

                    # í˜ì´ì§€ë„¤ì´ì…˜ ì¢…ë£Œ ì¡°ê±´
                    if current_page_count < num_of_rows:
                        break
                else:
                    break

                page_no += 1

            except Exception as e:
                error_msg = f"ë™ê¸°í™” ëª©ë¡ í˜ì´ì§€ {page_no} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}"
                content_result["errors"].append(error_msg)
                break

        return content_result

    async def _collect_legal_dong_area_data(
        self,
        area_code: str,
        sync_batch_id: str,
        store_raw: bool,
        auto_transform: bool,
    ) -> Dict:
        """íŠ¹ì • ì§€ì—­ì˜ ë²•ì •ë™ ì½”ë“œ ë°ì´í„° ìˆ˜ì§‘"""

        area_result = {
            "area_code": area_code,
            "raw_records": 0,
            "processed_records": 0,
            "pages_collected": 0,
            "raw_data_ids": [],
            "errors": []
        }

        page_no = 1
        num_of_rows = 1000

        while True:
            try:
                params = {
                    **self.default_params,
                    "lDongRegnCd": area_code,
                    "numOfRows": num_of_rows,
                    "pageNo": page_no
                }

                response = await self.api_client.call_api(
                    api_provider=APIProvider.KTO,
                    endpoint="ldongCode2",
                    params=params,
                    store_raw=store_raw
                )

                if response.success:
                    current_page_count = len(response.data.get("items", []))
                    area_result["raw_records"] += current_page_count
                    area_result["pages_collected"] += 1
                    area_result["raw_data_ids"].append(response.raw_data_id)

                    # ìë™ ë³€í™˜ ìˆ˜í–‰
                    if auto_transform and response.raw_data_id:
                        try:
                            transform_result = await self.transformation_pipeline.transform_raw_data(
                                response.raw_data_id
                            )

                            if transform_result.success:
                                # ë³€í™˜ëœ ë°ì´í„°ë¥¼ ë²•ì •ë™ ì½”ë“œ í…Œì´ë¸”ì— ì €ì¥
                                saved_count = await self._save_legal_dong_codes(
                                    transform_result.processed_data,
                                    sync_batch_id,
                                    response.raw_data_id
                                )
                                area_result["processed_records"] += saved_count

                        except Exception as e:
                            error_msg = f"ë²•ì •ë™ ì½”ë“œ ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨: {e}"
                            area_result["errors"].append(error_msg)

                    # í˜ì´ì§€ë„¤ì´ì…˜ ì¢…ë£Œ ì¡°ê±´
                    if current_page_count < num_of_rows:
                        break
                else:
                    break

                page_no += 1

            except Exception as e:
                error_msg = f"ë²•ì •ë™ ì½”ë“œ í˜ì´ì§€ {page_no} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}"
                area_result["errors"].append(error_msg)
                break

        return area_result

    async def _save_pet_tour_data(
        self,
        processed_data: List[Dict],
        sync_batch_id: str,
        raw_data_id: str,
    ) -> int:
        """ë°˜ë ¤ë™ë¬¼ ë™ë°˜ì—¬í–‰ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""

        if not processed_data:
            return 0

        try:
            saved_count = 0
            for data in processed_data:
                # í«íˆ¬ì–´ ì „ìš© í…Œì´ë¸”ì— ì €ì¥
                self.db_manager.execute_update(
                    """
                    INSERT INTO pet_tour_info (
                        content_id, title, address, area_code, content_type_id,
                        pet_info, pet_facilities, sync_batch_id, raw_data_id,
                        created_at, updated_at
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                    ON CONFLICT (content_id) DO UPDATE SET
                        title = EXCLUDED.title,
                        address = EXCLUDED.address,
                        pet_info = EXCLUDED.pet_info,
                        pet_facilities = EXCLUDED.pet_facilities,
                        sync_batch_id = EXCLUDED.sync_batch_id,
                        raw_data_id = EXCLUDED.raw_data_id,
                        updated_at = EXCLUDED.updated_at
                    """,
                    (
                        data.get("content_id"),
                        data.get("title"),
                        data.get("address"),
                        data.get("area_code"),
                        data.get("content_type_id"),
                        data.get("pet_info"),
                        data.get("pet_facilities"),
                        sync_batch_id,
                        raw_data_id,
                        datetime.utcnow(),
                        datetime.utcnow(),
                    ),
                )
                saved_count += 1

            self.logger.info(f"í«íˆ¬ì–´ ë°ì´í„° {saved_count}ê±´ ì €ì¥ ì™„ë£Œ")
            return saved_count

        except Exception as e:
            self.logger.error(f"í«íˆ¬ì–´ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            return 0

    async def _save_classification_codes(
        self,
        processed_data: List[Dict],
        sync_batch_id: str,
        raw_data_id: str,
    ) -> int:
        """ë¶„ë¥˜ì²´ê³„ ì½”ë“œë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""

        if not processed_data:
            return 0

        try:
            saved_count = 0
            for data in processed_data:
                # ë¶„ë¥˜ì²´ê³„ ì½”ë“œ í…Œì´ë¸”ì— ì €ì¥
                self.db_manager.execute_update(
                    """
                    INSERT INTO classification_system_codes (
                        code, name, description, parent_code, level,
                        sync_batch_id, raw_data_id, created_at, updated_at
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                    ON CONFLICT (code) DO UPDATE SET
                        name = EXCLUDED.name,
                        description = EXCLUDED.description,
                        parent_code = EXCLUDED.parent_code,
                        level = EXCLUDED.level,
                        sync_batch_id = EXCLUDED.sync_batch_id,
                        raw_data_id = EXCLUDED.raw_data_id,
                        updated_at = EXCLUDED.updated_at
                    """,
                    (
                        data.get("code"),
                        data.get("name"),
                        data.get("description"),
                        data.get("parent_code"),
                        data.get("level"),
                        sync_batch_id,
                        raw_data_id,
                        datetime.utcnow(),
                        datetime.utcnow(),
                    ),
                )
                saved_count += 1

            self.logger.info(f"ë¶„ë¥˜ì²´ê³„ ì½”ë“œ {saved_count}ê±´ ì €ì¥ ì™„ë£Œ")
            return saved_count

        except Exception as e:
            self.logger.error(f"ë¶„ë¥˜ì²´ê³„ ì½”ë“œ ì €ì¥ ì‹¤íŒ¨: {e}")
            return 0

    async def _save_sync_list_data(
        self,
        processed_data: List[Dict],
        sync_batch_id: str,
        raw_data_id: str,
    ) -> int:
        """ë™ê¸°í™” ëª©ë¡ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""

        if not processed_data:
            return 0

        try:
            saved_count = 0
            for data in processed_data:
                # ë™ê¸°í™” ëª©ë¡ í…Œì´ë¸”ì— ì €ì¥
                self.db_manager.execute_update(
                    """
                    INSERT INTO area_based_sync_list (
                        content_id, title, content_type_id, area_code,
                        modified_time, creation_time, sync_batch_id, raw_data_id,
                        created_at, updated_at
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                    ON CONFLICT (content_id) DO UPDATE SET
                        title = EXCLUDED.title,
                        modified_time = EXCLUDED.modified_time,
                        sync_batch_id = EXCLUDED.sync_batch_id,
                        raw_data_id = EXCLUDED.raw_data_id,
                        updated_at = EXCLUDED.updated_at
                    """,
                    (
                        data.get("content_id"),
                        data.get("title"),
                        data.get("content_type_id"),
                        data.get("area_code"),
                        data.get("modified_time"),
                        data.get("creation_time"),
                        sync_batch_id,
                        raw_data_id,
                        datetime.utcnow(),
                        datetime.utcnow(),
                    ),
                )
                saved_count += 1

            self.logger.info(f"ë™ê¸°í™” ëª©ë¡ ë°ì´í„° {saved_count}ê±´ ì €ì¥ ì™„ë£Œ")
            return saved_count

        except Exception as e:
            self.logger.error(f"ë™ê¸°í™” ëª©ë¡ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            return 0

    async def _save_legal_dong_codes(
        self,
        processed_data: List[Dict],
        sync_batch_id: str,
        raw_data_id: str,
    ) -> int:
        """ë²•ì •ë™ ì½”ë“œë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""

        if not processed_data:
            return 0

        try:
            saved_count = 0
            for data in processed_data:
                # ë²•ì •ë™ ì½”ë“œ í…Œì´ë¸”ì— ì €ì¥
                self.db_manager.execute_update(
                    """
                    INSERT INTO legal_dong_codes (
                        area_code, sigungu_code, umd_code, ri_code,
                        area_name, sigungu_name, umd_name, ri_name,
                        sync_batch_id, raw_data_id, created_at, updated_at
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                    ON CONFLICT (area_code, sigungu_code, umd_code, ri_code) DO UPDATE SET
                        area_name = EXCLUDED.area_name,
                        sigungu_name = EXCLUDED.sigungu_name,
                        umd_name = EXCLUDED.umd_name,
                        ri_name = EXCLUDED.ri_name,
                        sync_batch_id = EXCLUDED.sync_batch_id,
                        raw_data_id = EXCLUDED.raw_data_id,
                        updated_at = EXCLUDED.updated_at
                    """,
                    (
                        data.get("area_code"),
                        data.get("sigungu_code"),
                        data.get("umd_code"),
                        data.get("ri_code"),
                        data.get("area_name"),
                        data.get("sigungu_name"),
                        data.get("umd_name"),
                        data.get("ri_name"),
                        sync_batch_id,
                        raw_data_id,
                        datetime.utcnow(),
                        datetime.utcnow(),
                    ),
                )
                saved_count += 1

            self.logger.info(f"ë²•ì •ë™ ì½”ë“œ {saved_count}ê±´ ì €ì¥ ì™„ë£Œ")
            return saved_count

        except Exception as e:
            self.logger.error(f"ë²•ì •ë™ ì½”ë“œ ì €ì¥ ì‹¤íŒ¨: {e}")
            return 0

    async def _save_processed_data(
        self,
        content_type: str,
        processed_data: List[Dict],
        raw_data_id: str,
        quality_score: float,
    ) -> int:
        """ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""

        if not processed_data:
            return 0

        try:
            target_table = self._get_target_table(content_type)

            saved_count = 0

            for item in processed_data:
                # raw_data_idì™€ í’ˆì§ˆ ì ìˆ˜ ì¶”ê°€
                self.logger.debug(f"ì›ë³¸ raw_data_id: {raw_data_id} (íƒ€ì…: {type(raw_data_id)})")
                # raw_data_idê°€ ìœ íš¨í•œ UUID í˜•ì‹ì¸ì§€ í™•ì¸í•˜ê³ , ì•„ë‹ˆë©´ Noneìœ¼ë¡œ ì„¤ì •
                try:
                    import uuid
                    uuid.UUID(str(raw_data_id))  # UUID ìœ íš¨ì„± ê²€ì‚¬
                    item["raw_data_id"] = raw_data_id
                except (ValueError, TypeError, AttributeError):
                    self.logger.warning(f"ìœ íš¨í•˜ì§€ ì•Šì€ raw_data_id: {raw_data_id}, NULLë¡œ ì„¤ì •")
                    item["raw_data_id"] = None
                item["data_quality_score"] = quality_score
                item["last_sync_at"] = datetime.utcnow()

                # í…Œì´ë¸”ë³„ ì €ì¥ ë¡œì§
                if target_table == "tourist_attractions":
                    self.db_manager.upsert_tourist_attraction(item)
                elif target_table == "accommodations":
                    self.db_manager.upsert_accommodation(item)
                elif target_table == "festivals_events":
                    self.db_manager.upsert_festival_event(item)
                elif target_table == "restaurants":
                    self.db_manager.upsert_restaurant(item)
                elif target_table == "leisure_sports":
                    # facility_nameì´ ì—†ê±°ë‚˜ ë¹ˆ ê°’ì´ë©´ ê¸°ë³¸ê°’ ëŒ€ì…
                    if not item.get("facility_name"):
                        item["facility_name"] = "ë¯¸ìƒ"
                    self.db_manager.upsert_leisure_sport(item)
                elif target_table == "cultural_facilities":
                    self.db_manager.upsert_cultural_facility(item)
                else:
                    self.logger.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í…Œì´ë¸”: {target_table}, ê´€ê´‘ì§€ë¡œ ì €ì¥")
                    self.db_manager.upsert_tourist_attraction(item)

                saved_count += 1

            self.logger.debug(
                f"ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {target_table} {saved_count}ê±´"
            )
            return saved_count

        except Exception as e:
            self.logger.error(f"ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            return 0

    def _get_target_table(self, content_type: str) -> str:
        """ì»¨í…ì¸  íƒ€ì…ì— ë”°ë¥¸ ëŒ€ìƒ í…Œì´ë¸” ê²°ì •"""
        table_mapping = {
            "12": "tourist_attractions",
            "14": "cultural_facilities",
            "15": "festivals_events",
            "25": "travel_courses",
            "28": "leisure_sports",
            "32": "accommodations",
            "38": "shopping",
            "39": "restaurants",
        }

        return table_mapping.get(content_type, "tourist_attractions")

    async def collect_area_codes(self, parent_code: Optional[str] = None) -> List[Dict]:
        """ì§€ì—­ ì½”ë“œ ì •ë³´ ìˆ˜ì§‘"""

        params = {**self.default_params, "numOfRows": 50}

        if parent_code:
            params["areaCode"] = parent_code

        async with self.api_client:
            response = await self.api_client.call_api(
                api_provider=APIProvider.KTO,
                endpoint="areaCode2",
                params=params,
                store_raw=True,
                cache_ttl=86400,  # 24ì‹œê°„ ìºì‹œ
            )

            if not response.success:
                self.logger.error(f"ì§€ì—­ ì½”ë“œ ìˆ˜ì§‘ ì‹¤íŒ¨: {response.error}")
                return []

            # ì‘ë‹µì—ì„œ ì•„ì´í…œ ì¶”ì¶œ
            items = response.data.get("response", {}).get("body", {}).get("items", {})
            if not items or "item" not in items:
                return []

            area_items = items["item"]
            if isinstance(area_items, dict):
                area_items = [area_items]

            # ì§€ì—­ ì½”ë“œ ì •ë³´ ë³€í™˜
            area_codes = []
            for item in area_items:
                area_info = {
                    "region_code": item.get("code"),
                    "region_name": item.get("name"),
                    "parent_region_code": parent_code,
                    "region_level": 1 if not parent_code else 2,
                    "data_source": "KTO_API",
                    "raw_data_id": response.raw_data_id,
                    "processed_at": datetime.utcnow().isoformat(),
                }
                area_codes.append(area_info)

            self.logger.info(f"ì§€ì—­ ì½”ë“œ ìˆ˜ì§‘ ì™„ë£Œ: {len(area_codes)}ê°œ")
            return area_codes

    async def collect_detailed_area_codes(self) -> List[Dict]:
        """ì„¸ë¶€ ì§€ì—­ ì½”ë“œ ì •ë³´ ìˆ˜ì§‘ (ì‹œêµ°êµ¬)"""

        all_detailed_codes = []

        async with self.api_client:
            for area_code in self.area_codes:
                try:
                    detailed_codes = await self.collect_area_codes(area_code)
                    all_detailed_codes.extend(detailed_codes)

                    # API í˜¸ì¶œ ê°„ê²© ì¡°ì •
                    await asyncio.sleep(0.1)

                except Exception as e:
                    self.logger.error(f"ì„¸ë¶€ ì§€ì—­ ì½”ë“œ ìˆ˜ì§‘ ì‹¤íŒ¨ ({area_code}): {e}")

        self.logger.info(f"ì „ì²´ ì„¸ë¶€ ì§€ì—­ ì½”ë“œ ìˆ˜ì§‘ ì™„ë£Œ: {len(all_detailed_codes)}ê°œ")
        return all_detailed_codes

    async def collect_category_codes(
        self, content_type_id: Optional[str] = None
    ) -> List[Dict]:
        """ì¹´í…Œê³ ë¦¬ ì½”ë“œ ì •ë³´ ìˆ˜ì§‘"""

        params = {**self.default_params, "numOfRows": 100}

        if content_type_id:
            params["contentTypeId"] = content_type_id

        async with self.api_client:
            response = await self.api_client.call_api(
                api_provider=APIProvider.KTO,
                endpoint="categoryCode2",
                params=params,
                store_raw=True,
                cache_ttl=86400,  # 24ì‹œê°„ ìºì‹œ
            )

            if not response.success:
                self.logger.error(f"ì¹´í…Œê³ ë¦¬ ì½”ë“œ ìˆ˜ì§‘ ì‹¤íŒ¨: {response.error}")
                return []

            # ì‘ë‹µì—ì„œ ì•„ì´í…œ ì¶”ì¶œ ë° ë³€í™˜
            items = response.data.get("response", {}).get("body", {}).get("items", {})
            if not items or "item" not in items:
                return []

            category_items = items["item"]
            if isinstance(category_items, dict):
                category_items = [category_items]

            category_codes = []
            for item in category_items:
                category_info = {
                    "category_code": item.get("code"),
                    "category_name": item.get("name"),
                    "content_type_id": content_type_id,
                    "data_source": "KTO_API",
                    "raw_data_id": response.raw_data_id,
                    "processed_at": datetime.utcnow().isoformat(),
                }
                category_codes.append(category_info)

            self.logger.info(f"ì¹´í…Œê³ ë¦¬ ì½”ë“œ ìˆ˜ì§‘ ì™„ë£Œ: {len(category_codes)}ê°œ")
            return category_codes

    async def collect_detailed_information(
        self,
        content_types: List[str],
        max_content_ids: int = 100,
        store_raw: bool = True,
        auto_transform: bool = True
    ) -> Dict:
        """ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ (detailCommon2, detailIntro2, detailInfo2, detailImage2)"""

        result = {
            "total_raw_records": 0,
            "total_processed_records": 0,
            "content_types_processed": {},
            "errors": []
        }

        for content_type_id in content_types:
            content_name = self.content_types.get(content_type_id, f"unknown_{content_type_id}")
            self.logger.info(f"=== {content_name} ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘ ===")

            try:
                # ê¸°ì¡´ content_idë“¤ ê°€ì ¸ì˜¤ê¸°
                content_ids = await self._get_existing_content_ids(content_type_id, max_content_ids)

                if not content_ids:
                    self.logger.warning(f"{content_name}: ê¸°ì¡´ ì½˜í…ì¸  IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    continue

                content_result = {
                    "content_ids_processed": len(content_ids),
                    "detail_common": 0,
                    "detail_intro": 0,
                    "detail_info": 0,
                    "detail_images": 0,
                    "errors": []
                }

                # ê° content_idì— ëŒ€í•´ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
                for i, content_id in enumerate(content_ids):
                    if i % 10 == 0:
                        self.logger.info(f"{content_name}: {i+1}/{len(content_ids)} ì²˜ë¦¬ ì¤‘...")

                    try:
                        # 1. detailCommon2 - ê¸°ë³¸ ìƒì„¸ ì •ë³´
                        detail_common = await self.collect_detail_common(content_id, content_type_id, store_raw)
                        if detail_common:
                            content_result["detail_common"] += 1
                            result["total_raw_records"] += 1

                        # 2. detailIntro2 - ì†Œê°œ ì •ë³´
                        detail_intro = await self.collect_detail_intro(content_id, content_type_id, store_raw)
                        if detail_intro:
                            content_result["detail_intro"] += 1
                            result["total_raw_records"] += 1

                        # 3. detailInfo2 - ì¶”ê°€ ìƒì„¸ ì •ë³´
                        detail_info = await self.collect_detail_info(content_id, content_type_id, store_raw)
                        if detail_info:
                            content_result["detail_info"] += 1
                            result["total_raw_records"] += 1

                        # 4. detailImage2 - ì´ë¯¸ì§€ ì •ë³´
                        detail_images = await self.collect_detail_images(content_id, store_raw)
                        if detail_images:
                            content_result["detail_images"] += 1
                            result["total_raw_records"] += 1

                        # API í˜¸ì¶œ ê°„ê²© ì¡°ì •
                        await asyncio.sleep(0.2)

                    except Exception as e:
                        error_msg = f"{content_name} {content_id} ìƒì„¸ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}"
                        content_result["errors"].append(error_msg)
                        self.logger.error(error_msg)

                result["content_types_processed"][content_name] = content_result
                self.logger.info(f"{content_name} ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ: {content_result}")

            except Exception as e:
                error_msg = f"{content_name} ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}"
                result["errors"].append(error_msg)
                self.logger.error(error_msg)

        return result

    async def _get_existing_content_ids(self, content_type_id: str, limit: int) -> List[str]:
        """ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ content_id ì¡°íšŒ"""
        table_name = self.content_types.get(content_type_id)
        if not table_name:
            return []

        try:
            # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê¸°ì¡´ content_idë“¤ ì¡°íšŒ
            query = f"SELECT content_id FROM {table_name} WHERE content_id IS NOT NULL LIMIT %s"
            result = self.db_manager.execute_query(query, (limit,))
            return [row[0] for row in result if row[0]]
        except Exception as e:
            self.logger.error(f"ê¸°ì¡´ content_id ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    async def collect_detail_common(self, content_id: str, content_type_id: str, store_raw: bool = True) -> Optional[Dict]:
        """detailCommon2 API í˜¸ì¶œ - ê¸°ë³¸ ìƒì„¸ ì •ë³´"""
        try:
            params = {
                **self.default_params,
                "contentId": content_id
            }

            async with self.api_client:
                response = await self.api_client.call_api(
                    api_provider=APIProvider.KTO,
                    endpoint="detailCommon2",
                    params=params,
                    store_raw=store_raw
                )

            if response.success and response.data:
                # ìƒˆë¡œìš´ ë³€í™˜ íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                process_result = await self.transformation_pipeline.process_detailed_api_response(
                    api_name="detailCommon2",
                    content_id=content_id,
                    content_type_id=content_type_id,
                    raw_response=response.data,
                    raw_data_id=response.raw_data_id
                )

                if process_result.get('success'):
                    self.logger.debug(f"âœ… detailCommon2 ì •ë³´ ì²˜ë¦¬ ì„±ê³µ: {content_id}")
                else:
                    self.logger.warning(f"âš ï¸ detailCommon2 ì •ë³´ ì²˜ë¦¬ ì‹¤íŒ¨: {content_id} - {process_result.get('error')}")

                # ì›ë³¸ ë°ì´í„° ë°˜í™˜ (í•˜ìœ„ í˜¸í™˜ì„±)
                items = response.data.get("items", {}).get("item", [])
                if items and not isinstance(items, list):
                    items = [items]
                return items[0] if items else None

        except Exception as e:
            self.logger.error(f"detailCommon2 í˜¸ì¶œ ì‹¤íŒ¨ (content_id: {content_id}): {e}")

        return None

    async def collect_detail_intro(self, content_id: str, content_type_id: str, store_raw: bool = True) -> Optional[Dict]:
        """detailIntro2 API í˜¸ì¶œ - ì†Œê°œ ì •ë³´"""
        try:
            params = {
                **self.default_params,
                "contentId": content_id,
                "contentTypeId": content_type_id
            }

            async with self.api_client:
                response = await self.api_client.call_api(
                    api_provider=APIProvider.KTO,
                    endpoint="detailIntro2",
                    params=params,
                    store_raw=store_raw
                )

            if response.success and response.data:
                # ë°ì´í„° íƒ€ì… í™•ì¸
                if not isinstance(response.data, dict):
                    self.logger.warning(f"âš ï¸ detailIntro2 ì‘ë‹µì´ dictê°€ ì•„ë‹˜: {type(response.data)} - {response.data}")
                    return None

                # ìƒˆë¡œìš´ ë³€í™˜ íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                process_result = await self.transformation_pipeline.process_detailed_api_response(
                    api_name="detailIntro2",
                    content_id=content_id,
                    content_type_id=content_type_id,
                    raw_response=response.data,
                    raw_data_id=response.raw_data_id
                )

                if process_result.get('success'):
                    self.logger.debug(f"âœ… detailIntro2 ì •ë³´ ì²˜ë¦¬ ì„±ê³µ: {content_id}")
                else:
                    self.logger.warning(f"âš ï¸ detailIntro2 ì •ë³´ ì²˜ë¦¬ ì‹¤íŒ¨: {content_id} - {process_result.get('error')}")

                # ì›ë³¸ ë°ì´í„° ë°˜í™˜ (í•˜ìœ„ í˜¸í™˜ì„±)
                try:
                    items_data = response.data.get("items", {})
                    # itemsê°€ ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš° ì²˜ë¦¬
                    if items_data == "" or not items_data:
                        self.logger.debug(f"detailIntro2 ë°ì´í„° ì—†ìŒ: {response.data}")
                        return None

                    items = items_data.get("item", [])
                    if items and not isinstance(items, list):
                        items = [items]
                    return items[0] if items else None
                except (AttributeError, TypeError) as e:
                    self.logger.warning(f"âš ï¸ detailIntro2 ë°ì´í„° ì ‘ê·¼ ì‹¤íŒ¨: {e} - {response.data}")
                    return None

        except Exception as e:
            self.logger.error(f"detailIntro2 í˜¸ì¶œ ì‹¤íŒ¨ (content_id: {content_id}): {e}")

        return None

    async def collect_detail_info(self, content_id: str, content_type_id: str, store_raw: bool = True) -> Optional[List[Dict]]:
        """detailInfo2 API í˜¸ì¶œ - ì¶”ê°€ ìƒì„¸ ì •ë³´"""
        try:
            params = {
                **self.default_params,
                "contentId": content_id,
                "contentTypeId": content_type_id
            }

            async with self.api_client:
                response = await self.api_client.call_api(
                    api_provider=APIProvider.KTO,
                    endpoint="detailInfo2",
                    params=params,
                    store_raw=store_raw
                )

            if response.success and response.data:
                # ë°ì´í„° íƒ€ì… í™•ì¸
                if not isinstance(response.data, dict):
                    self.logger.warning(f"âš ï¸ detailInfo2 ì‘ë‹µì´ dictê°€ ì•„ë‹˜: {type(response.data)} - {response.data}")
                    return None

                # ìƒˆë¡œìš´ ë³€í™˜ íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                process_result = await self.transformation_pipeline.process_detailed_api_response(
                    api_name="detailInfo2",
                    content_id=content_id,
                    content_type_id=content_type_id,
                    raw_response=response.data,
                    raw_data_id=response.raw_data_id
                )

                if process_result.get('success'):
                    self.logger.debug(f"âœ… detailInfo2 ì •ë³´ ì²˜ë¦¬ ì„±ê³µ: {content_id}")
                else:
                    self.logger.warning(f"âš ï¸ detailInfo2 ì •ë³´ ì²˜ë¦¬ ì‹¤íŒ¨: {content_id} - {process_result.get('error')}")

                # ì›ë³¸ ë°ì´í„° ë°˜í™˜ (í•˜ìœ„ í˜¸í™˜ì„±)
                try:
                    items_data = response.data.get("items", {})
                    # itemsê°€ ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš° ì²˜ë¦¬
                    if items_data == "" or not items_data:
                        self.logger.debug(f"detailInfo2 ë°ì´í„° ì—†ìŒ: {response.data}")
                        return None

                    items = items_data.get("item", [])
                    if items and not isinstance(items, list):
                        items = [items]
                    return items
                except (AttributeError, TypeError) as e:
                    self.logger.warning(f"âš ï¸ detailInfo2 ë°ì´í„° ì ‘ê·¼ ì‹¤íŒ¨: {e} - {response.data}")
                    return None

        except Exception as e:
            self.logger.error(f"detailInfo2 í˜¸ì¶œ ì‹¤íŒ¨ (content_id: {content_id}): {e}")

        return None

    async def collect_detail_images(self, content_id: str, store_raw: bool = True) -> Optional[List[Dict]]:
        """detailImage2 API í˜¸ì¶œ - ì´ë¯¸ì§€ ì •ë³´"""
        try:
            params = {
                **self.default_params,
                "contentId": content_id,
                "imageYN": "Y"
            }

            async with self.api_client:
                response = await self.api_client.call_api(
                    api_provider=APIProvider.KTO,
                    endpoint="detailImage2",
                    params=params,
                    store_raw=store_raw
                )

            if response.success and response.data:
                # ë°ì´í„° íƒ€ì… í™•ì¸
                if not isinstance(response.data, dict):
                    self.logger.warning(f"âš ï¸ detailImage2 ì‘ë‹µì´ dictê°€ ì•„ë‹˜: {type(response.data)} - {response.data}")
                    return None

                # ìƒˆë¡œìš´ ë³€í™˜ íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                # detailImage2ëŠ” content_type_idê°€ ì—†ìœ¼ë¯€ë¡œ ê¸°ë³¸ê°’ ì‚¬ìš©
                process_result = await self.transformation_pipeline.process_detailed_api_response(
                    api_name="detailImage2",
                    content_id=content_id,
                    content_type_id="12",  # ê¸°ë³¸ê°’ (ê´€ê´‘ì§€)
                    raw_response=response.data,
                    raw_data_id=response.raw_data_id
                )

                if process_result.get('success'):
                    self.logger.debug(f"âœ… detailImage2 ì •ë³´ ì²˜ë¦¬ ì„±ê³µ: {content_id}")
                else:
                    self.logger.warning(f"âš ï¸ detailImage2 ì •ë³´ ì²˜ë¦¬ ì‹¤íŒ¨: {content_id} - {process_result.get('error')}")

                # ì›ë³¸ ë°ì´í„° ë°˜í™˜ (í•˜ìœ„ í˜¸í™˜ì„±)
                try:
                    items_data = response.data.get("items", {})
                    # itemsê°€ ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš° ì²˜ë¦¬
                    if items_data == "" or not items_data:
                        self.logger.debug(f"detailImage2 ë°ì´í„° ì—†ìŒ: {response.data}")
                        return None

                    items = items_data.get("item", [])
                    if items and not isinstance(items, list):
                        items = [items]
                    return items
                except (AttributeError, TypeError) as e:
                    self.logger.warning(f"âš ï¸ detailImage2 ë°ì´í„° ì ‘ê·¼ ì‹¤íŒ¨: {e} - {response.data}")
                    return None

        except Exception as e:
            self.logger.error(f"detailImage2 í˜¸ì¶œ ì‹¤íŒ¨ (content_id: {content_id}): {e}")

        return None

    async def collect_detailed_info_parallel(
        self,
        content_ids: List[str],
        content_type_id: str,
        store_raw: bool = True,
        batch_size: int = 50
    ) -> Dict:
        """ë³‘ë ¬ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘"""

        if not self.enable_parallel or not self.concurrent_manager:
            self.logger.warning("ë³‘ë ¬ ì²˜ë¦¬ê°€ ë¹„í™œì„±í™”ë¨. ìˆœì°¨ ì²˜ë¦¬ë¡œ ëŒ€ì²´")
            return await self._collect_detailed_info_sequential(content_ids, content_type_id, store_raw)

        self.logger.info(f"ë³‘ë ¬ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘: {len(content_ids)}ê°œ ì»¨í…ì¸ ")

        # ê²°ê³¼ ì´ˆê¸°í™”
        result = {
            "started_at": datetime.utcnow().isoformat(),
            "content_type_id": content_type_id,
            "total_content_ids": len(content_ids),
            "detail_common": 0,
            "detail_intro": 0,
            "detail_info": 0,
            "detail_images": 0,
            "successful_content_ids": [],
            "failed_content_ids": [],
            "errors": []
        }

        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
        for batch_start in range(0, len(content_ids), batch_size):
            batch_end = min(batch_start + batch_size, len(content_ids))
            batch_content_ids = content_ids[batch_start:batch_end]

            self.logger.info(f"ë°°ì¹˜ {batch_start//batch_size + 1} ì²˜ë¦¬ ì¤‘: {len(batch_content_ids)}ê°œ ì»¨í…ì¸ ")

            # ë°°ì¹˜ë³„ API ì‘ì—… ìƒì„±
            batch_tasks = []

            for content_id in batch_content_ids:
                # detailCommon2 ì‘ì—…
                batch_tasks.append(APICallTask(
                    task_id=f"detail_common_{content_id}",
                    api_provider=APIProvider.KTO,
                    endpoint="detailCommon2",
                    params={
                        **self.default_params,
                        "contentId": content_id,
                        "contentTypeId": content_type_id
                    },
                    callback=self._create_api_callback("detailCommon2", content_id, content_type_id, store_raw),
                    priority=APICallPriority.HIGH
                ))

                # detailIntro2 ì‘ì—…
                batch_tasks.append(APICallTask(
                    task_id=f"detail_intro_{content_id}",
                    api_provider=APIProvider.KTO,
                    endpoint="detailIntro2",
                    params={
                        **self.default_params,
                        "contentId": content_id,
                        "contentTypeId": content_type_id
                    },
                    callback=self._create_api_callback("detailIntro2", content_id, content_type_id, store_raw),
                    priority=APICallPriority.MEDIUM
                ))

                # detailInfo2 ì‘ì—…
                batch_tasks.append(APICallTask(
                    task_id=f"detail_info_{content_id}",
                    api_provider=APIProvider.KTO,
                    endpoint="detailInfo2",
                    params={
                        **self.default_params,
                        "contentId": content_id,
                        "contentTypeId": content_type_id
                    },
                    callback=self._create_api_callback("detailInfo2", content_id, content_type_id, store_raw),
                    priority=APICallPriority.MEDIUM
                ))

                # detailImage2 ì‘ì—…
                batch_tasks.append(APICallTask(
                    task_id=f"detail_images_{content_id}",
                    api_provider=APIProvider.KTO,
                    endpoint="detailImage2",
                    params={
                        **self.default_params,
                        "contentId": content_id,
                        "imageYN": "Y"
                    },
                    callback=self._create_api_callback("detailImage2", content_id, "12", store_raw),
                    priority=APICallPriority.LOW
                ))

            # ë°°ì¹˜ ë³‘ë ¬ ì‹¤í–‰
            batch_results = await self.concurrent_manager.execute_batch(batch_tasks)

            # ê²°ê³¼ ì§‘ê³„
            content_success_count = {}

            for batch_result in batch_results:
                if batch_result['success']:
                    # ì‘ì—… IDì—ì„œ API íƒ€ì…ê³¼ content_id ì¶”ì¶œ
                    task_id = batch_result['task_id']

                    # API íƒ€ì… ë§¤í•‘
                    if task_id.startswith('detail_common_'):
                        api_type = 'detail_common'
                        content_id = task_id.replace('detail_common_', '')
                    elif task_id.startswith('detail_intro_'):
                        api_type = 'detail_intro'
                        content_id = task_id.replace('detail_intro_', '')
                    elif task_id.startswith('detail_info_'):
                        api_type = 'detail_info'
                        content_id = task_id.replace('detail_info_', '')
                    elif task_id.startswith('detail_images_'):
                        api_type = 'detail_images'
                        content_id = task_id.replace('detail_images_', '')
                    else:
                        self.logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ì‘ì—… ID í˜•ì‹: {task_id}")
                        continue

                    result[api_type] += 1

                    # ì»¨í…ì¸ ë³„ ì„±ê³µ ì¹´ìš´íŠ¸
                    if content_id not in content_success_count:
                        content_success_count[content_id] = 0
                    content_success_count[content_id] += 1

                else:
                    # ì‹¤íŒ¨í•œ ì‘ì—… ì²˜ë¦¬
                    task_id = batch_result['task_id']

                    # API íƒ€ì… ë§¤í•‘
                    if task_id.startswith('detail_common_'):
                        api_type = 'detail_common'
                        content_id = task_id.replace('detail_common_', '')
                    elif task_id.startswith('detail_intro_'):
                        api_type = 'detail_intro'
                        content_id = task_id.replace('detail_intro_', '')
                    elif task_id.startswith('detail_info_'):
                        api_type = 'detail_info'
                        content_id = task_id.replace('detail_info_', '')
                    elif task_id.startswith('detail_images_'):
                        api_type = 'detail_images'
                        content_id = task_id.replace('detail_images_', '')
                    else:
                        api_type = 'unknown'
                        content_id = task_id

                    error_msg = f"{content_id} {api_type}: {batch_result['error']}"
                    result["errors"].append(error_msg)

            # ì„±ê³µ/ì‹¤íŒ¨í•œ ì»¨í…ì¸  ID ë¶„ë¥˜
            for content_id in batch_content_ids:
                success_count = content_success_count.get(content_id, 0)
                if success_count > 0:
                    result["successful_content_ids"].append({
                        "content_id": content_id,
                        "successful_apis": success_count,
                        "total_apis": 4
                    })
                else:
                    result["failed_content_ids"].append(content_id)

            # ë°°ì¹˜ ê°„ ëŒ€ê¸° (API ê³¼ë¶€í•˜ ë°©ì§€)
            if batch_end < len(content_ids):
                await asyncio.sleep(1.0)

        result["completed_at"] = datetime.utcnow().isoformat()

        # í†µê³„ ìš”ì•½
        successful_content_count = len(result["successful_content_ids"])
        success_rate = (successful_content_count / len(content_ids) * 100) if content_ids else 0

        self.logger.info(
            f"ë³‘ë ¬ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ: {successful_content_count}/{len(content_ids)} ì»¨í…ì¸  ì„±ê³µ "
            f"({success_rate:.1f}%)"
        )

        return result

    def _create_api_callback(self, api_name: str, content_id: str, content_type_id: str, store_raw: bool):
        """API ì½œë°± í•¨ìˆ˜ ìƒì„±"""

        async def callback(endpoint: str, params: Dict) -> Optional[Dict]:
            async with self.api_client:
                response = await self.api_client.call_api(
                    api_provider=APIProvider.KTO,
                    endpoint=endpoint,
                    params=params,
                    store_raw=store_raw
                )

            if response.success and response.data:
                # ë°ì´í„° ë³€í™˜ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬
                process_result = await self.transformation_pipeline.process_detailed_api_response(
                    api_name=api_name,
                    content_id=content_id,
                    content_type_id=content_type_id,
                    raw_response=response.data,
                    raw_data_id=response.raw_data_id
                )

                if process_result.get('success'):
                    self.logger.debug(f"âœ… {api_name} ì •ë³´ ì²˜ë¦¬ ì„±ê³µ: {content_id}")
                    return response.data
                else:
                    self.logger.warning(f"âš ï¸ {api_name} ì •ë³´ ì²˜ë¦¬ ì‹¤íŒ¨: {content_id} - {process_result.get('error')}")
                    return None

            return None

        return callback

    async def _collect_detailed_info_sequential(
        self,
        content_ids: List[str],
        content_type_id: str,
        store_raw: bool = True
    ) -> Dict:
        """ìˆœì°¨ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ (ê¸°ì¡´ ë°©ì‹)"""

        self.logger.info(f"ìˆœì°¨ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘: {len(content_ids)}ê°œ ì»¨í…ì¸ ")

        result = {
            "started_at": datetime.utcnow().isoformat(),
            "content_type_id": content_type_id,
            "total_content_ids": len(content_ids),
            "detail_common": 0,
            "detail_intro": 0,
            "detail_info": 0,
            "detail_images": 0,
            "successful_content_ids": [],
            "failed_content_ids": [],
            "errors": []
        }

        for i, content_id in enumerate(content_ids):
            if i % 10 == 0:
                self.logger.info(f"ìˆœì°¨ ì²˜ë¦¬: {i+1}/{len(content_ids)} ì§„í–‰ ì¤‘...")

            success_count = 0

            try:
                # detailCommon2
                detail_common = await self.collect_detail_common(content_id, content_type_id, store_raw)
                if detail_common:
                    result["detail_common"] += 1
                    success_count += 1

                # detailIntro2
                detail_intro = await self.collect_detail_intro(content_id, content_type_id, store_raw)
                if detail_intro:
                    result["detail_intro"] += 1
                    success_count += 1

                # detailInfo2
                detail_info = await self.collect_detail_info(content_id, content_type_id, store_raw)
                if detail_info:
                    result["detail_info"] += 1
                    success_count += 1

                # detailImage2
                detail_images = await self.collect_detail_images(content_id, store_raw)
                if detail_images:
                    result["detail_images"] += 1
                    success_count += 1

                if success_count > 0:
                    result["successful_content_ids"].append({
                        "content_id": content_id,
                        "successful_apis": success_count,
                        "total_apis": 4
                    })
                else:
                    result["failed_content_ids"].append(content_id)

                # API í˜¸ì¶œ ê°„ê²©
                await asyncio.sleep(0.2)

            except Exception as e:
                error_msg = f"{content_id} ìƒì„¸ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}"
                result["errors"].append(error_msg)
                result["failed_content_ids"].append(content_id)
                self.logger.error(error_msg)

        result["completed_at"] = datetime.utcnow().isoformat()

        return result

    async def get_api_statistics(self) -> Dict:
        """API í˜¸ì¶œ í†µê³„ ì¡°íšŒ"""

        try:
            stats = self.db_manager.get_api_call_statistics("KTO")
            return {
                "provider": "KTO",
                "today_calls": stats.get("today_calls", 0),
                "success_rate": stats.get("success_rate", 0.0),
                "avg_response_time_ms": stats.get("avg_response_time_ms", 0),
                "cache_hit_rate": stats.get("cache_hit_rate", 0.0),
                "last_call_at": stats.get("last_call_at"),
                "total_raw_data_size_mb": stats.get("total_raw_data_size_mb", 0.0),
            }
        except Exception as e:
            self.logger.error(f"API í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_unified_kto_client = None


def get_unified_kto_client() -> UnifiedKTOClient:
    """í†µí•© KTO í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _unified_kto_client
    if _unified_kto_client is None:
        _unified_kto_client = UnifiedKTOClient()
    return _unified_kto_client
