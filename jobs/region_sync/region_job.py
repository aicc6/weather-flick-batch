"""
ì§€ì—­ ì •ë³´ ë™ê¸°í™” ë°°ì¹˜ ì‘ì—… (regions í…Œì´ë¸” ê¸°ë°˜)

ê¸°ìƒì²­ê³¼ í•œêµ­ê´€ê´‘ê³µì‚¬ APIì˜ ì§€ì—­ ì •ë³´ë¥¼ í†µí•© ê´€ë¦¬í•˜ëŠ” ë°°ì¹˜ ì‘ì—…
- KTO ì§€ì—­ ì½”ë“œ ë™ê¸°í™”
- KMA ì§€ì—­ ë§¤í•‘ ë™ê¸°í™”  
- ì¢Œí‘œ ë³€í™˜ ê²€ì¦
- ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬
"""

import asyncio
import logging
import json
from typing import Dict, Any
from datetime import datetime

from app.core.base_job import BaseJob
from app.services.region_service import RegionService
from app.core.database_manager import get_db_manager


class RegionJob(BaseJob):
    """ì§€ì—­ ì •ë³´ ë™ê¸°í™” ì‘ì—… (regions í…Œì´ë¸” ê¸°ë°˜)"""
    
    def __init__(self):
        super().__init__()
        self.job_name = "region_sync_job"
        self.region_service = RegionService()
        self.db_manager = get_db_manager()
        
    async def execute(self) -> Dict[str, Any]:
        """ì§€ì—­ ì •ë³´ ë™ê¸°í™” ì‹¤í–‰"""
        
        self.logger.info("ğŸš€ ì§€ì—­ ì •ë³´ ë™ê¸°í™” ì‘ì—… ì‹œì‘ (regions í…Œì´ë¸” ê¸°ë°˜)")
        
        # ë°°ì¹˜ ì‘ì—… ë¡œê·¸ ì‹œì‘
        job_log_id = self._create_batch_job_log()
        
        results = {
            'job_log_id': job_log_id,
            'kto_sync': None,
            'kma_sync': None,
            'coordinate_validation': None,
            'data_quality_check': None,
            'statistics': None,
            'overall_status': 'running'
        }
        
        try:
            # 1. KTO ì§€ì—­ ì •ë³´ ë™ê¸°í™”
            self.logger.info("ğŸ“ 1ë‹¨ê³„: KTO ì§€ì—­ ì •ë³´ ë™ê¸°í™”")
            kto_result = await self._run_with_timeout(
                self.region_service.sync_kto_regions(),
                timeout=600  # 10ë¶„
            )
            results['kto_sync'] = kto_result
            
            # 2. KMA ì§€ì—­ ì •ë³´ ë™ê¸°í™”
            self.logger.info("ğŸŒ¤ï¸ 2ë‹¨ê³„: KMA ì§€ì—­ ì •ë³´ ë™ê¸°í™”")
            kma_result = await self._run_with_timeout(
                self.region_service.sync_kma_regions(),
                timeout=600  # 10ë¶„
            )
            results['kma_sync'] = kma_result
            
            # 3. ì¢Œí‘œ ë³€í™˜ ê²€ì¦
            self.logger.info("ğŸ” 3ë‹¨ê³„: ì¢Œí‘œ ë³€í™˜ ì •í™•ë„ ê²€ì¦")
            validation_result = await self._run_with_timeout(
                self.region_service.validate_coordinate_transformations(
                    sample_size=50
                ),
                timeout=300  # 5ë¶„
            )
            results['coordinate_validation'] = validation_result
            
            # 4. ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬
            self.logger.info("âœ… 4ë‹¨ê³„: ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬")
            quality_result = await self._run_with_timeout(
                self._check_data_quality(),
                timeout=180  # 3ë¶„
            )
            results['data_quality_check'] = quality_result
            
            # 5. í†µê³„ ìˆ˜ì§‘
            self.logger.info("ğŸ“Š 5ë‹¨ê³„: ì§€ì—­ ì •ë³´ í†µê³„ ìˆ˜ì§‘")
            stats = await self._run_with_timeout(
                self._collect_statistics(),
                timeout=60  # 1ë¶„
            )
            results['statistics'] = stats
            
            # ì „ì²´ ìƒíƒœ ê²°ì •
            if all([
                results.get('kto_sync', {}).get('status') == 'success',
                results.get('kma_sync', {}).get('status') == 'success',
                results.get('coordinate_validation', {}).get('overall_status') == 'success'
            ]):
                results['overall_status'] = 'success'
            else:
                results['overall_status'] = 'partial_success'
                
            self.logger.info(f"âœ… ì§€ì—­ ì •ë³´ ë™ê¸°í™” ì™„ë£Œ: {results['overall_status']}")
            
        except Exception as e:
            self.logger.error(f"âŒ ì§€ì—­ ì •ë³´ ë™ê¸°í™” ì‹¤íŒ¨: {e}")
            results['overall_status'] = 'failure'
            results['error'] = str(e)
            
        finally:
            # ë°°ì¹˜ ì‘ì—… ë¡œê·¸ ì—…ë°ì´íŠ¸
            self._update_batch_job_log(
                job_log_id,
                results['overall_status'],
                results
            )
            
        return results
    
    async def _check_data_quality(self) -> Dict[str, Any]:
        """ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬"""
        try:
            quality_checks = {
                'missing_coordinates': 0,
                'duplicate_codes': 0,
                'invalid_mappings': 0,
                'orphan_regions': 0,
                'total_issues': 0
            }
            
            # 1. ì¢Œí‘œ ëˆ„ë½ í™•ì¸
            query = """
            SELECT COUNT(*) as count
            FROM regions
            WHERE (latitude IS NULL OR longitude IS NULL)
              AND is_active = true
            """
            result = self.db_manager.fetch_one(query)
            quality_checks['missing_coordinates'] = result['count'] if result else 0
            
            # 2. ì¤‘ë³µ ì½”ë“œ í™•ì¸
            query = """
            SELECT COUNT(*) as count
            FROM (
                SELECT region_code, COUNT(*) as cnt
                FROM regions
                WHERE is_active = true
                GROUP BY region_code
                HAVING COUNT(*) > 1
            ) duplicates
            """
            result = self.db_manager.fetch_one(query)
            quality_checks['duplicate_codes'] = result['count'] if result else 0
            
            # 3. ê³ ì•„ ì§€ì—­ í™•ì¸ (ë¶€ëª¨ê°€ ì—†ëŠ” í•˜ìœ„ ì§€ì—­)
            query = """
            SELECT COUNT(*) as count
            FROM regions r1
            WHERE r1.parent_region_code IS NOT NULL
              AND r1.is_active = true
              AND NOT EXISTS (
                  SELECT 1 FROM regions r2
                  WHERE r2.region_code = r1.parent_region_code
                  AND r2.is_active = true
              )
            """
            result = self.db_manager.fetch_one(query)
            quality_checks['orphan_regions'] = result['count'] if result else 0
            
            # ì „ì²´ ì´ìŠˆ ìˆ˜ ê³„ì‚°
            quality_checks['total_issues'] = sum([
                quality_checks['missing_coordinates'],
                quality_checks['duplicate_codes'],
                quality_checks['orphan_regions']
            ])
            
            quality_checks['status'] = 'pass' if quality_checks['total_issues'] == 0 else 'warning'
            
            return quality_checks
            
        except Exception as e:
            self.logger.error(f"ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬ ì‹¤íŒ¨: {e}")
            return {'status': 'error', 'error': str(e)}
    
    async def _collect_statistics(self) -> Dict[str, Any]:
        """ì§€ì—­ ì •ë³´ í†µê³„ ìˆ˜ì§‘"""
        try:
            stats = {}
            
            # ì „ì²´ ì§€ì—­ ìˆ˜
            query = "SELECT COUNT(*) as count FROM regions WHERE is_active = true"
            result = self.db_manager.fetch_one(query)
            stats['total_regions'] = result['count'] if result else 0
            
            # ë ˆë²¨ë³„ ì§€ì—­ ìˆ˜
            query = """
            SELECT region_level, COUNT(*) as count
            FROM regions
            WHERE is_active = true
            GROUP BY region_level
            ORDER BY region_level
            """
            results = self.db_manager.fetch_all(query)
            stats['regions_by_level'] = {
                row['region_level']: row['count'] 
                for row in results
            } if results else {}
            
            # ì¢Œí‘œ ì •ë³´ê°€ ìˆëŠ” ì§€ì—­ ìˆ˜
            query = """
            SELECT COUNT(*) as count
            FROM regions
            WHERE latitude IS NOT NULL 
              AND longitude IS NOT NULL
              AND is_active = true
            """
            result = self.db_manager.fetch_one(query)
            stats['regions_with_coordinates'] = result['count'] if result else 0
            
            # ê·¸ë¦¬ë“œ ì •ë³´ê°€ ìˆëŠ” ì§€ì—­ ìˆ˜
            query = """
            SELECT COUNT(*) as count
            FROM regions
            WHERE grid_x IS NOT NULL 
              AND grid_y IS NOT NULL
              AND is_active = true
            """
            result = self.db_manager.fetch_one(query)
            stats['regions_with_grid'] = result['count'] if result else 0
            
            return stats
            
        except Exception as e:
            self.logger.error(f"í†µê³„ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    async def _run_with_timeout(self, coro, timeout: int):
        """íƒ€ì„ì•„ì›ƒê³¼ í•¨ê»˜ ì½”ë£¨í‹´ ì‹¤í–‰"""
        try:
            # ì½”ë£¨í‹´ì´ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
            if not asyncio.iscoroutine(coro):
                return coro
            
            return await asyncio.wait_for(coro, timeout=timeout)
        except asyncio.TimeoutError:
            self.logger.error(f"ì‘ì—…ì´ {timeout}ì´ˆ ë‚´ì— ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return {'status': 'timeout', 'timeout_seconds': timeout}


if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # ì‘ì—… ì‹¤í–‰
    job = RegionJob()
    result = asyncio.run(job.execute())
    
    print("\n=== ì§€ì—­ ì •ë³´ ë™ê¸°í™” ê²°ê³¼ ===")
    print(json.dumps(result, indent=2, ensure_ascii=False))