#!/usr/bin/env python3
"""
Weather Forecast í…Œì´ë¸” ì„±ëŠ¥ ìµœì í™” ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
1. í˜„ì¬ í…Œì´ë¸” ë° ì¸ë±ìŠ¤ ìƒíƒœ ë¶„ì„
2. ì¶”ê°€ ì¸ë±ìŠ¤ ìƒì„±
3. ì¿¼ë¦¬ ì„±ëŠ¥ ì¸¡ì •
4. ìµœì í™” ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±

ì‹¤í–‰ ë°©ë²•:
python scripts/optimize_weather_performance.py [--analyze-only]

ì˜µì…˜:
--analyze-only : ë¶„ì„ë§Œ ìˆ˜í–‰í•˜ê³  ì¸ë±ìŠ¤ ìƒì„±í•˜ì§€ ì•ŠìŒ
"""

import sys
import argparse
import time
from pathlib import Path
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from app.core.database_manager import DatabaseManager
from app.core.logger import get_logger


class WeatherPerformanceOptimizer:
    """ë‚ ì”¨ ë°ì´í„° í…Œì´ë¸” ì„±ëŠ¥ ìµœì í™” ê´€ë¦¬ì"""
    
    def __init__(self):
        self.logger = get_logger(__name__)
        self.db_manager = DatabaseManager()
        
    def analyze_current_state(self) -> dict:
        """í˜„ì¬ í…Œì´ë¸” ìƒíƒœ ë¶„ì„"""
        analysis = {}
        
        try:
            # í…Œì´ë¸” í¬ê¸° ë¶„ì„
            size_query = """
            SELECT 
                pg_size_pretty(pg_total_relation_size('weather_forecast')) as total_size,
                pg_size_pretty(pg_relation_size('weather_forecast')) as table_size,
                pg_size_pretty(pg_total_relation_size('weather_forecast') - pg_relation_size('weather_forecast')) as indexes_size
            """
            
            size_info = self.db_manager.fetch_one(size_query)
            analysis['table_sizes'] = size_info
            
            # ë ˆì½”ë“œ ìˆ˜ ë° ë‚ ì§œ ë²”ìœ„
            stats_query = """
            SELECT 
                COUNT(*) as total_records,
                MIN(forecast_date) as earliest_date,
                MAX(forecast_date) as latest_date,
                COUNT(DISTINCT region_code) as unique_regions,
                COUNT(DISTINCT forecast_date) as unique_dates
            FROM weather_forecast
            """
            
            stats_info = self.db_manager.fetch_one(stats_query)
            analysis['table_stats'] = stats_info
            
            # ê¸°ì¡´ ì¸ë±ìŠ¤ í™•ì¸
            index_query = """
            SELECT 
                indexname,
                indexdef,
                pg_size_pretty(pg_relation_size(indexname::regclass)) as index_size
            FROM pg_indexes 
            WHERE tablename = 'weather_forecast'
            ORDER BY indexname
            """
            
            indexes = self.db_manager.fetch_all(index_query)
            analysis['existing_indexes'] = indexes
            
            # ë°ì´í„° í’ˆì§ˆ ì²´í¬
            quality_query = """
            SELECT 
                COUNT(*) as total_records,
                COUNT(*) FILTER (WHERE min_temp IS NULL) as missing_min_temp,
                COUNT(*) FILTER (WHERE max_temp IS NULL) as missing_max_temp,
                COUNT(*) FILTER (WHERE weather_condition IS NULL OR weather_condition = '') as missing_condition,
                COUNT(*) FILTER (WHERE forecast_date < CURRENT_DATE - INTERVAL '30 days') as old_records
            FROM weather_forecast
            """
            
            quality_info = self.db_manager.fetch_one(quality_query)
            analysis['data_quality'] = quality_info
            
            self.logger.info(f"í˜„ì¬ ìƒíƒœ ë¶„ì„ ì™„ë£Œ: {stats_info['total_records']}ê±´ì˜ ë ˆì½”ë“œ")
            
        except Exception as e:
            self.logger.error(f"í˜„ì¬ ìƒíƒœ ë¶„ì„ ì‹¤íŒ¨: {e}")
            
        return analysis
    
    def measure_query_performance(self) -> dict:
        """ì£¼ìš” ì¿¼ë¦¬ ì„±ëŠ¥ ì¸¡ì •"""
        performance_results = {}
        
        # í…ŒìŠ¤íŠ¸í•  ì¿¼ë¦¬ë“¤
        test_queries = {
            "region_latest_forecast": """
                SELECT region_code, forecast_date, forecast_time, min_temp, max_temp
                FROM weather_forecast 
                WHERE region_code = '11' 
                ORDER BY forecast_date DESC, forecast_time DESC 
                LIMIT 10
            """,
            
            "date_range_search": """
                SELECT COUNT(*) 
                FROM weather_forecast 
                WHERE forecast_date BETWEEN CURRENT_DATE AND CURRENT_DATE + INTERVAL '7 days'
            """,
            
            "coordinate_lookup": """
                SELECT region_code, forecast_date, min_temp, max_temp
                FROM weather_forecast 
                WHERE nx = 60 AND ny = 127 
                AND forecast_date >= CURRENT_DATE
                ORDER BY forecast_date, forecast_time
                LIMIT 20
            """,
            
            "quality_check": """
                SELECT COUNT(*) 
                FROM weather_forecast 
                WHERE min_temp IS NULL OR max_temp IS NULL 
                OR weather_condition IS NULL
            """
        }
        
        for query_name, query_sql in test_queries.items():
            try:
                # EXPLAIN ANALYZE ì‹¤í–‰
                explain_query = f"EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON) {query_sql}"
                
                start_time = time.time()
                explain_result = self.db_manager.fetch_one(explain_query)
                execution_time = time.time() - start_time
                
                performance_results[query_name] = {
                    "execution_time": execution_time,
                    "explain_result": explain_result
                }
                
                self.logger.debug(f"ì¿¼ë¦¬ ì„±ëŠ¥ ì¸¡ì • ì™„ë£Œ: {query_name} ({execution_time:.3f}ì´ˆ)")
                
            except Exception as e:
                self.logger.warning(f"ì¿¼ë¦¬ ì„±ëŠ¥ ì¸¡ì • ì‹¤íŒ¨ [{query_name}]: {e}")
                performance_results[query_name] = {"error": str(e)}
        
        return performance_results
    
    def apply_optimizations(self) -> bool:
        """ì„±ëŠ¥ ìµœì í™” ì ìš© (ê°œë³„ ì¸ë±ìŠ¤ ìƒì„±)"""
        try:
            optimization_file = project_root / "database" / "migrations" / "004_additional_weather_indexes.sql"
            
            if not optimization_file.exists():
                self.logger.error(f"ìµœì í™” íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {optimization_file}")
                return False
                
            with open(optimization_file, 'r', encoding='utf-8') as f:
                optimization_content = f.read()
            
            self.logger.info("ì„±ëŠ¥ ìµœì í™” ì ìš© ì‹œì‘...")
            
            # CREATE INDEX ë¬¸ë“¤ì„ ê°œë³„ì ìœ¼ë¡œ ì‹¤í–‰
            import re
            
            # CREATE INDEX ë¬¸ë“¤ë§Œ ì¶”ì¶œ (ë¬¸ì œê°€ ìˆëŠ” íŒ¨í„´ ì œì™¸)
            index_statements = re.findall(
                r'CREATE INDEX[^;]+;', 
                optimization_content, 
                re.IGNORECASE | re.MULTILINE | re.DOTALL
            )
            
            # ANALYZE ë¬¸ ì¶”ì¶œ
            analyze_statements = re.findall(
                r'ANALYZE[^;]*;', 
                optimization_content, 
                re.IGNORECASE
            )
            
            success_count = 0
            total_count = len(index_statements)
            
            for statement in index_statements:
                try:
                    statement = statement.strip()
                    
                    # ë¬¸ì œê°€ ìˆëŠ” íŒ¨í„´ ê°ì§€ ë° ìˆ˜ì •
                    if 'CURRENT_DATE' in statement and 'WHERE' in statement:
                        # CURRENT_DATE ê´€ë ¨ WHERE ì ˆ ì œê±°
                        statement = re.sub(r'\s*WHERE\s+.*CURRENT_DATE[^;]*', '', statement)
                        self.logger.info("IMMUTABLE í•¨ìˆ˜ ë¬¸ì œë¡œ WHERE ì ˆ ì œê±°ë¨")
                    
                    self.db_manager.execute_update(statement)
                    index_name = re.search(r'idx_\w+', statement)
                    if index_name:
                        self.logger.info(f"ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ: {index_name.group()}")
                    success_count += 1
                    
                except Exception as e:
                    index_name = re.search(r'idx_\w+', statement)
                    error_context = index_name.group() if index_name else "ì•Œ ìˆ˜ ì—†ëŠ” ì¸ë±ìŠ¤"
                    self.logger.warning(f"ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨ [{error_context}]: {e}")
                    
                    # íŠ¹ì • ì˜¤ë¥˜ì— ëŒ€í•œ ìë™ ë³µêµ¬ ì‹œë„
                    if 'IMMUTABLE' in str(e) and 'WHERE' in statement:
                        try:
                            # WHERE ì ˆ ì œê±° í›„ ì¬ì‹œë„
                            fixed_statement = re.sub(r'\s*WHERE\s+[^;]*', ';', statement)
                            self.db_manager.execute_update(fixed_statement)
                            self.logger.info(f"ìë™ ë³µêµ¬ ì„±ê³µ: {error_context} (WHERE ì ˆ ì œê±°)")
                            success_count += 1
                        except Exception as retry_error:
                            self.logger.error(f"ìë™ ë³µêµ¬ ì‹¤íŒ¨ [{error_context}]: {retry_error}")
            
            # ANALYZE ì‹¤í–‰
            for analyze_stmt in analyze_statements:
                try:
                    self.db_manager.execute_update(analyze_stmt.strip())
                    self.logger.info("í…Œì´ë¸” í†µê³„ ì •ë³´ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                except Exception as e:
                    self.logger.warning(f"ANALYZE ì‹¤íŒ¨: {e}")
            
            self.logger.info(f"ì„±ëŠ¥ ìµœì í™” ì™„ë£Œ: {success_count}/{total_count}ê°œ ì¸ë±ìŠ¤ ìƒì„±ë¨")
            return success_count > 0
            
        except Exception as e:
            self.logger.error(f"ì„±ëŠ¥ ìµœì í™” ì ìš© ì‹¤íŒ¨: {e}")
            return False
    
    def generate_report(self, analysis: dict, performance_before: dict, performance_after: dict = None):
        """ìµœì í™” ë¦¬í¬íŠ¸ ìƒì„±"""
        report_lines = []
        report_lines.append("=" * 60)
        report_lines.append("Weather Forecasts í…Œì´ë¸” ì„±ëŠ¥ ë¶„ì„ ë¦¬í¬íŠ¸")
        report_lines.append(f"ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append("=" * 60)
        
        # í…Œì´ë¸” ì •ë³´
        if 'table_stats' in analysis:
            stats = analysis['table_stats']
            report_lines.append("\nğŸ“Š í…Œì´ë¸” í†µê³„:")
            report_lines.append(f"  - ì´ ë ˆì½”ë“œ ìˆ˜: {stats['total_records']:,}ê±´")
            report_lines.append(f"  - ê³ ìœ  ì§€ì—­ ìˆ˜: {stats['unique_regions']}ê°œ")
            report_lines.append(f"  - ì˜ˆë³´ ë‚ ì§œ ë²”ìœ„: {stats['earliest_date']} ~ {stats['latest_date']}")
            report_lines.append(f"  - ê³ ìœ  ë‚ ì§œ ìˆ˜: {stats['unique_dates']}ê°œ")
        
        # í…Œì´ë¸” í¬ê¸°
        if 'table_sizes' in analysis:
            sizes = analysis['table_sizes']
            report_lines.append("\nğŸ’¾ ì €ì¥ê³µê°„ ì‚¬ìš©ëŸ‰:")
            report_lines.append(f"  - ì „ì²´ í¬ê¸°: {sizes['total_size']}")
            report_lines.append(f"  - í…Œì´ë¸” í¬ê¸°: {sizes['table_size']}")
            report_lines.append(f"  - ì¸ë±ìŠ¤ í¬ê¸°: {sizes['indexes_size']}")
        
        # ì¸ë±ìŠ¤ ì •ë³´
        if 'existing_indexes' in analysis:
            indexes = analysis['existing_indexes']
            report_lines.append(f"\nğŸ” ì¸ë±ìŠ¤ í˜„í™© ({len(indexes)}ê°œ):")
            for idx in indexes:
                report_lines.append(f"  - {idx['indexname']}: {idx.get('index_size', 'N/A')}")
        
        # ë°ì´í„° í’ˆì§ˆ
        if 'data_quality' in analysis:
            quality = analysis['data_quality']
            report_lines.append("\nğŸ¯ ë°ì´í„° í’ˆì§ˆ:")
            report_lines.append(f"  - ëˆ„ë½ëœ ìµœì €ì˜¨ë„: {quality['missing_min_temp']}ê±´")
            report_lines.append(f"  - ëˆ„ë½ëœ ìµœê³ ì˜¨ë„: {quality['missing_max_temp']}ê±´")
            report_lines.append(f"  - ëˆ„ë½ëœ ë‚ ì”¨ìƒíƒœ: {quality['missing_condition']}ê±´")
            report_lines.append(f"  - 30ì¼ ì´ì „ ë°ì´í„°: {quality['old_records']}ê±´")
        
        # ì„±ëŠ¥ ì¸¡ì • ê²°ê³¼
        if performance_before:
            report_lines.append("\nâš¡ ì¿¼ë¦¬ ì„±ëŠ¥ ì¸¡ì •:")
            for query_name, result in performance_before.items():
                if 'execution_time' in result:
                    report_lines.append(f"  - {query_name}: {result['execution_time']:.3f}ì´ˆ")
                else:
                    report_lines.append(f"  - {query_name}: ì˜¤ë¥˜ ë°œìƒ")
        
        # ê°œì„  ê¶Œì¥ì‚¬í•­
        report_lines.append("\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
        
        if 'data_quality' in analysis:
            quality = analysis['data_quality']
            if quality['missing_min_temp'] > 0 or quality['missing_max_temp'] > 0:
                report_lines.append("  - ëˆ„ë½ëœ ì˜¨ë„ ë°ì´í„° ë³´ì™„ í•„ìš”")
            if quality['old_records'] > 1000:
                report_lines.append("  - ì˜¤ë˜ëœ ì˜ˆë³´ ë°ì´í„° ì•„ì¹´ì´ë¹™ ê³ ë ¤")
        
        report_lines.append("  - ì •ê¸°ì ì¸ VACUUM ANALYZE ì‹¤í–‰")
        report_lines.append("  - ë°°ì¹˜ ì‘ì—… ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§")
        
        report_lines.append("\n" + "=" * 60)
        
        # ë¦¬í¬íŠ¸ ì €ì¥
        report_content = "\n".join(report_lines)
        
        report_file = project_root / "logs" / f"weather_performance_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        report_file.parent.mkdir(exist_ok=True)
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(report_content)
        print(f"\nğŸ“„ ìƒì„¸ ë¦¬í¬íŠ¸ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {report_file}")
    
    def run_optimization(self, analyze_only: bool = False):
        """ì „ì²´ ìµœì í™” í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        self.logger.info("=== Weather Forecasts ì„±ëŠ¥ ìµœì í™” ì‹œì‘ ===")
        
        # 1ë‹¨ê³„: í˜„ì¬ ìƒíƒœ ë¶„ì„
        analysis = self.analyze_current_state()
        
        # 2ë‹¨ê³„: ì„±ëŠ¥ ì¸¡ì • (ìµœì í™” ì „)
        performance_before = self.measure_query_performance()
        
        performance_after = None
        
        if not analyze_only:
            # 3ë‹¨ê³„: ìµœì í™” ì ìš©
            if self.apply_optimizations():
                # 4ë‹¨ê³„: ì„±ëŠ¥ ì¸¡ì • (ìµœì í™” í›„)
                performance_after = self.measure_query_performance()
            else:
                self.logger.error("ìµœì í™” ì ìš© ì‹¤íŒ¨")
        
        # 5ë‹¨ê³„: ë¦¬í¬íŠ¸ ìƒì„±
        self.generate_report(analysis, performance_before, performance_after)
        
        self.logger.info("=== Weather Forecasts ì„±ëŠ¥ ìµœì í™” ì™„ë£Œ ===")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='Weather Forecasts í…Œì´ë¸” ì„±ëŠ¥ ìµœì í™”')
    parser.add_argument('--analyze-only', action='store_true', 
                       help='ë¶„ì„ë§Œ ìˆ˜í–‰í•˜ê³  ìµœì í™”ëŠ” ì ìš©í•˜ì§€ ì•ŠìŒ')
    
    args = parser.parse_args()
    
    optimizer = WeatherPerformanceOptimizer()
    
    try:
        optimizer.run_optimization(analyze_only=args.analyze_only)
        
        if args.analyze_only:
            print("âœ… ì„±ëŠ¥ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print("âœ… ì„±ëŠ¥ ìµœì í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            
        print("ğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
        print("  1. ë°°ì¹˜ ì‘ì—… ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§")
        print("  2. ì¿¼ë¦¬ ì‹¤í–‰ ê³„íš í™•ì¸")
        print("  3. ì •ê¸°ì ì¸ VACUUM ANALYZE ìŠ¤ì¼€ì¤„ë§")
        
        return 0
        
    except Exception as e:
        print(f"âŒ ìµœì í™” í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {e}")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)