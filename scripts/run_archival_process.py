#!/usr/bin/env python3
"""
ì•„ì¹´ì´ë¹™ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

API ì›ë³¸ ë°ì´í„°ì˜ ì•„ì¹´ì´ë¹™ì„ ìˆ˜ë™ìœ¼ë¡œ ì‹¤í–‰í•˜ê±°ë‚˜ ìŠ¤ì¼€ì¤„ë§í•˜ê¸° ìœ„í•œ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.
"""

import sys
import os
import asyncio
import logging
import argparse

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.archiving.archival_engine import get_archival_engine
from app.archiving.backup_manager import get_backup_manager, BackupConfiguration
from app.archiving.archival_policies import get_archival_policy_manager

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def run_archival_process(api_provider: str = None, endpoint: str = None,
                             dry_run: bool = False, cleanup_old_backups: bool = False):
    """ì•„ì¹´ì´ë¹™ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
    logger.info("ğŸ—„ï¸ ì•„ì¹´ì´ë¹™ í”„ë¡œì„¸ìŠ¤ ì‹œì‘")

    try:
        # ì•„ì¹´ì´ë¹™ ì—”ì§„ ì´ˆê¸°í™”
        backup_config = BackupConfiguration(
            base_backup_path="./data/backups",
            max_concurrent_backups=3,
            verify_integrity=True,
            auto_cleanup_days=30
        )
        backup_manager = get_backup_manager(backup_config)
        archival_engine = get_archival_engine(backup_manager)

        # ì •ì±… ìƒíƒœ í™•ì¸
        policy_manager = get_archival_policy_manager()
        policy_stats = policy_manager.get_policy_statistics()
        logger.info(f"ğŸ“‹ ì•„ì¹´ì´ë¹™ ì •ì±… ìƒíƒœ: {policy_stats['enabled_policies']}ê°œ í™œì„±í™”ë¨")

        # ì•„ì¹´ì´ë¹™ ì‹¤í–‰
        summary = await archival_engine.run_archival_process(
            api_provider=api_provider,
            endpoint=endpoint,
            dry_run=dry_run
        )

        # ê²°ê³¼ ë¦¬í¬íŠ¸
        logger.info("ğŸ“Š ì•„ì¹´ì´ë¹™ ê²°ê³¼ ìš”ì•½:")
        logger.info(f"  â€¢ ì´ í›„ë³´: {summary.total_candidates}ê°œ")
        logger.info(f"  â€¢ ì²˜ë¦¬ëœ í•­ëª©: {summary.processed_items}ê°œ")
        logger.info(f"  â€¢ ì„±ê³µí•œ ë°±ì—…: {summary.successful_backups}ê°œ")
        logger.info(f"  â€¢ ì‹¤íŒ¨í•œ ë°±ì—…: {summary.failed_backups}ê°œ")
        logger.info(f"  â€¢ ê±´ë„ˆë›´ í•­ëª©: {summary.skipped_items}ê°œ")
        logger.info(f"  â€¢ ì›ë³¸ í¬ê¸°: {summary.total_original_size_mb:.2f} MB")
        logger.info(f"  â€¢ ì••ì¶• í¬ê¸°: {summary.total_compressed_size_mb:.2f} MB")
        logger.info(f"  â€¢ í‰ê·  ì••ì¶•ë¥ : {summary.average_compression_ratio:.1f}%")
        logger.info(f"  â€¢ ì²˜ë¦¬ ì‹œê°„: {summary.processing_time_seconds:.2f}ì´ˆ")

        # ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬ (ì˜µì…˜)
        if cleanup_old_backups and not dry_run:
            logger.info("ğŸ§¹ ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬ ì‹œì‘")
            cleaned_count = await backup_manager.cleanup_old_backups()
            logger.info(f"âœ… ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬ ì™„ë£Œ: {cleaned_count}ê°œ ì‚­ì œ")

        # ì „ì²´ í†µê³„
        archival_stats = archival_engine.get_archival_statistics()
        logger.info("ğŸ“ˆ ì•„ì¹´ì´ë¹™ ì—”ì§„ í†µê³„:")
        logger.info(f"  â€¢ ì´ ì‹¤í–‰ íšŸìˆ˜: {archival_stats['engine_statistics']['total_runs']}")
        logger.info(f"  â€¢ ì´ ì²˜ë¦¬ í•­ëª©: {archival_stats['engine_statistics']['total_items_processed']}")
        logger.info(f"  â€¢ ì´ ë°±ì—… ìƒì„±: {archival_stats['engine_statistics']['total_backups_created']}")
        logger.info(f"  â€¢ ì´ ì•„ì¹´ì´ë¹™ ë°ì´í„°: {archival_stats['engine_statistics']['total_data_archived_mb']:.2f} MB")

        logger.info("âœ… ì•„ì¹´ì´ë¹™ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ")

    except Exception as e:
        logger.error(f"âŒ ì•„ì¹´ì´ë¹™ í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {e}")
        raise


async def show_policy_information():
    """ì•„ì¹´ì´ë¹™ ì •ì±… ì •ë³´ í‘œì‹œ"""
    logger.info("ğŸ“‹ ì•„ì¹´ì´ë¹™ ì •ì±… ì •ë³´")

    policy_manager = get_archival_policy_manager()
    policies = policy_manager.get_all_policies()

    for policy_id, policy in policies.items():
        logger.info(f"\nì •ì±…: {policy.name}")
        logger.info(f"  â€¢ ID: {policy_id}")
        logger.info(f"  â€¢ ì œê³µì: {policy.api_provider}")
        logger.info(f"  â€¢ í™œì„±í™”: {policy.enabled}")
        logger.info(f"  â€¢ ê·œì¹™ ìˆ˜: {len(policy.rules)}")

        for rule in policy.rules:
            logger.info(f"    - {rule.name}")
            logger.info(f"      íŠ¸ë¦¬ê±°: {rule.trigger.value}")
            logger.info(f"      ì¡°ê±´: {rule.condition}")
            logger.info(f"      ì••ì¶•: {rule.compression.value}")
            logger.info(f"      ì €ì¥ ìœ„ì¹˜: {rule.target_location.value}")
            logger.info(f"      ë³´ì¡´ ê¸°ê°„: {rule.retention_days}ì¼")


async def show_backup_statistics():
    """ë°±ì—… í†µê³„ í‘œì‹œ"""
    logger.info("ğŸ“Š ë°±ì—… í†µê³„")

    backup_manager = get_backup_manager()
    stats = backup_manager.get_backup_statistics()

    logger.info(f"ì´ ë°±ì—… ìˆ˜: {stats['total_backups']}")
    logger.info(f"ì„±ê³µí•œ ë°±ì—…: {stats['successful_backups']}")
    logger.info(f"ì‹¤íŒ¨í•œ ë°±ì—…: {stats['failed_backups']}")
    logger.info(f"ì›ë³¸ ì´ í¬ê¸°: {stats['total_original_size_bytes'] / (1024*1024):.2f} MB")
    logger.info(f"ì••ì¶• ì´ í¬ê¸°: {stats['total_compressed_size_bytes'] / (1024*1024):.2f} MB")
    logger.info(f"í‰ê·  ì••ì¶•ë¥ : {stats['average_compression_ratio']:.1f}%")

    logger.info("\nìƒíƒœë³„ ë°±ì—… ìˆ˜:")
    for status, count in stats['backup_by_status'].items():
        logger.info(f"  â€¢ {status}: {count}ê°œ")

    logger.info("\nì œê³µìë³„ ë°±ì—… ìˆ˜:")
    for provider, count in stats['backup_by_provider'].items():
        logger.info(f"  â€¢ {provider}: {count}ê°œ")


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="ì•„ì¹´ì´ë¹™ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰")
    parser.add_argument("--provider", help="íŠ¹ì • API ì œê³µìë§Œ ì²˜ë¦¬ (ì˜ˆ: KTO, KMA)")
    parser.add_argument("--endpoint", help="íŠ¹ì • ì—”ë“œí¬ì¸íŠ¸ë§Œ ì²˜ë¦¬")
    parser.add_argument("--dry-run", action="store_true", help="ì‹¤ì œ ì‹¤í–‰ ì—†ì´ ë¶„ì„ë§Œ ìˆ˜í–‰")
    parser.add_argument("--cleanup", action="store_true", help="ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬")
    parser.add_argument("--show-policies", action="store_true", help="ì•„ì¹´ì´ë¹™ ì •ì±… ì •ë³´ í‘œì‹œ")
    parser.add_argument("--show-stats", action="store_true", help="ë°±ì—… í†µê³„ í‘œì‹œ")

    args = parser.parse_args()

    try:
        if args.show_policies:
            await show_policy_information()
        elif args.show_stats:
            await show_backup_statistics()
        else:
            await run_archival_process(
                api_provider=args.provider,
                endpoint=args.endpoint,
                dry_run=args.dry_run,
                cleanup_old_backups=args.cleanup
            )

    except KeyboardInterrupt:
        logger.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())