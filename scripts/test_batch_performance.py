#!/usr/bin/env python3
"""
ë°°ì¹˜ INSERT ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
1. ê¸°ì¡´ ë°©ì‹ vs ë°°ì¹˜ ìµœì í™” ë°©ì‹ ì„±ëŠ¥ ë¹„êµ
2. ë‹¤ì–‘í•œ ë°°ì¹˜ í¬ê¸°ë³„ ì„±ëŠ¥ ì¸¡ì •
3. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
4. ìµœì ì˜ ë°°ì¹˜ ì„¤ì • ì¶”ì²œ

ì‹¤í–‰ ë°©ë²•:
python scripts/test_batch_performance.py [--test-size 1000] [--batch-sizes 100,500,1000,2000]

ì˜µì…˜:
--test-size: í…ŒìŠ¤íŠ¸í•  ë ˆì½”ë“œ ìˆ˜ (ê¸°ë³¸: 1000)
--batch-sizes: í…ŒìŠ¤íŠ¸í•  ë°°ì¹˜ í¬ê¸°ë“¤ (ê¸°ë³¸: 100,500,1000,2000)
--skip-legacy: ê¸°ì¡´ ë°©ì‹ í…ŒìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸°
"""

import sys
import argparse
import asyncio
import time
import tracemalloc
import uuid
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Any
import random
import statistics

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from app.core.batch_insert_optimizer import (
    BatchInsertOptimizer, 
    BatchConfig, 
    BatchResult,
    optimize_weather_current_insert,
    optimize_weather_forecast_insert
)
from app.core.database_manager import DatabaseManager
from app.core.logger import get_logger


class BatchPerformanceTester:
    """ë°°ì¹˜ INSERT ì„±ëŠ¥ í…ŒìŠ¤í„°"""
    
    def __init__(self):
        self.logger = get_logger(__name__)
        self.db_manager = DatabaseManager()
        self.test_results = []
        
    def generate_test_weather_data(self, count: int) -> List[Dict[str, Any]]:
        """í…ŒìŠ¤íŠ¸ìš© ë‚ ì”¨ ë°ì´í„° ìƒì„±"""
        
        test_data = []
        base_time = datetime.now()
        
        regions = ["ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ê´‘ì£¼", "ëŒ€ì „", "ìš¸ì‚°"]
        weather_conditions = ["ë§‘ìŒ", "íë¦¼", "ë¹„", "ëˆˆ", "ì•ˆê°œ"]
        
        for i in range(count):
            data = {
                "region_code": f"{random.randint(11, 50):02d}",
                "region_name": random.choice(regions),
                "temperature": round(random.uniform(-10, 35), 1),
                "humidity": random.randint(30, 95),
                "precipitation": round(random.uniform(0, 50), 1),
                "wind_speed": round(random.uniform(0, 20), 1),
                "wind_direction": random.randint(0, 360),
                "atmospheric_pressure": round(random.uniform(950, 1050), 1),
                "weather_condition": random.choice(weather_conditions),
                "visibility": round(random.uniform(0.1, 20), 1),
                "observed_at": base_time + timedelta(minutes=i)
            }
            test_data.append(data)
            
        return test_data
    
    def generate_test_forecast_data(self, count: int) -> List[Dict[str, Any]]:
        """í…ŒìŠ¤íŠ¸ìš© ì˜ˆë³´ ë°ì´í„° ìƒì„±"""
        
        test_data = []
        base_date = datetime.now().date()
        
        regions = ["ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ê´‘ì£¼", "ëŒ€ì „", "ìš¸ì‚°"]
        weather_conditions = ["ë§‘ìŒ", "íë¦¼", "ë¹„", "ëˆˆ", "ì•ˆê°œ"]
        forecast_times = ["0000", "0300", "0600", "0900", "1200", "1500", "1800", "2100"]
        
        for i in range(count):
            forecast_date = base_date + timedelta(days=i // 100)  # ë‚ ì§œ ë¶„ì‚°
            
            data = {
                "region_code": f"{random.randint(11, 50):02d}",
                "region_name": random.choice(regions),
                "nx": random.randint(50, 150),
                "ny": random.randint(100, 200),
                "forecast_date": forecast_date,
                "forecast_time": random.choice(forecast_times),
                "temperature": round(random.uniform(-10, 35), 1),
                "min_temp": round(random.uniform(-15, 25), 1),
                "max_temp": round(random.uniform(0, 40), 1),
                "weather_condition": random.choice(weather_conditions),
                "forecast_type": random.choice(["short", "medium"])
            }
            test_data.append(data)
            
        return test_data
    
    async def test_legacy_insert_method(
        self, 
        test_data: List[Dict[str, Any]], 
        table_type: str = "current"
    ) -> Dict[str, Any]:
        """ê¸°ì¡´ ë°©ì‹ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (ì‹œë®¬ë ˆì´ì…˜)"""
        
        start_time = time.time()
        tracemalloc.start()
        
        try:
            # ê¸°ì¡´ ë°©ì‹ ì‹œë®¬ë ˆì´ì…˜ (ê°œë³„ INSERT)
            processed_count = 0
            
            for data in test_data:
                # ì‹¤ì œ INSERTëŠ” í•˜ì§€ ì•Šê³  ì‹œê°„ë§Œ ì†Œëª¨
                await asyncio.sleep(0.001)  # ê°œë³„ INSERT ì˜¤ë²„í—¤ë“œ ì‹œë®¬ë ˆì´ì…˜
                processed_count += 1
                
                # 100ê°œë§ˆë‹¤ ì§„í–‰ë¥  ë¡œê¹…
                if processed_count % 100 == 0:
                    self.logger.debug(f"ê¸°ì¡´ ë°©ì‹ ì§„í–‰ë¥ : {processed_count}/{len(test_data)}")
            
            execution_time = time.time() - start_time
            current_memory, peak_memory = tracemalloc.get_traced_memory()
            
            return {
                "method": "legacy",
                "table_type": table_type,
                "records": len(test_data),
                "execution_time": execution_time,
                "records_per_second": len(test_data) / execution_time if execution_time > 0 else 0,
                "memory_peak_mb": peak_memory / 1024 / 1024,
                "memory_current_mb": current_memory / 1024 / 1024,
                "success_rate": 1.0
            }
            
        finally:
            tracemalloc.stop()
    
    async def test_batch_insert_method(
        self, 
        test_data: List[Dict[str, Any]], 
        batch_size: int,
        table_type: str = "current"
    ) -> Dict[str, Any]:
        """ë°°ì¹˜ INSERT ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        
        start_time = time.time()
        tracemalloc.start()
        
        try:
            config = BatchConfig(
                batch_size=batch_size,
                max_memory_mb=50,
                retry_attempts=1  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì¬ì‹œë„ ìµœì†Œí™”
            )
            
            # ì •ìƒì ì¸ UUID ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)
            raw_data_id = str(uuid.uuid4())
            
            if table_type == "current":
                result = await optimize_weather_current_insert(test_data, raw_data_id, config)
            elif table_type == "forecast":
                result = await optimize_weather_forecast_insert(test_data, raw_data_id, config)
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í…Œì´ë¸” íƒ€ì…: {table_type}")
            
            execution_time = time.time() - start_time
            current_memory, peak_memory = tracemalloc.get_traced_memory()
            
            return {
                "method": "batch_optimized",
                "table_type": table_type,
                "batch_size": batch_size,
                "records": result.total_records,
                "successful_records": result.successful_records,
                "execution_time": execution_time,
                "records_per_second": len(test_data) / execution_time if execution_time > 0 else 0,
                "memory_peak_mb": peak_memory / 1024 / 1024,
                "memory_current_mb": current_memory / 1024 / 1024,
                "success_rate": result.success_rate,
                "batch_execution_time": result.execution_time,
                "batch_records_per_second": result.records_per_second
            }
            
        finally:
            tracemalloc.stop()
    
    async def run_performance_comparison(
        self, 
        test_size: int, 
        batch_sizes: List[int],
        skip_legacy: bool = False
    ):
        """ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        
        self.logger.info(f"ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹œì‘: {test_size}ê±´ ë ˆì½”ë“œ")
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        current_weather_data = self.generate_test_weather_data(test_size)
        forecast_data = self.generate_test_forecast_data(test_size)
        
        self.logger.info(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± ì™„ë£Œ: í˜„ì¬ë‚ ì”¨ {len(current_weather_data)}ê±´, ì˜ˆë³´ {len(forecast_data)}ê±´")
        
        # ê¸°ì¡´ ë°©ì‹ í…ŒìŠ¤íŠ¸ (ì‹œë®¬ë ˆì´ì…˜)
        if not skip_legacy:
            self.logger.info("ê¸°ì¡´ ë°©ì‹ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì¤‘...")
            legacy_current = await self.test_legacy_insert_method(current_weather_data, "current")
            legacy_forecast = await self.test_legacy_insert_method(forecast_data, "forecast")
            
            self.test_results.extend([legacy_current, legacy_forecast])
            
            self.logger.info(f"ê¸°ì¡´ ë°©ì‹ - í˜„ì¬ë‚ ì”¨: {legacy_current['records_per_second']:.1f} records/sec")
            self.logger.info(f"ê¸°ì¡´ ë°©ì‹ - ì˜ˆë³´: {legacy_forecast['records_per_second']:.1f} records/sec")
        
        # ë°°ì¹˜ ìµœì í™” ë°©ì‹ í…ŒìŠ¤íŠ¸
        for batch_size in batch_sizes:
            self.logger.info(f"ë°°ì¹˜ í¬ê¸° {batch_size} í…ŒìŠ¤íŠ¸ ì¤‘...")
            
            # í˜„ì¬ ë‚ ì”¨ í…ŒìŠ¤íŠ¸
            batch_current = await self.test_batch_insert_method(
                current_weather_data, batch_size, "current"
            )
            
            # ì˜ˆë³´ ë°ì´í„° í…ŒìŠ¤íŠ¸
            batch_forecast = await self.test_batch_insert_method(
                forecast_data, batch_size, "forecast"
            )
            
            self.test_results.extend([batch_current, batch_forecast])
            
            self.logger.info(
                f"ë°°ì¹˜ í¬ê¸° {batch_size} - í˜„ì¬ë‚ ì”¨: {batch_current['records_per_second']:.1f} records/sec, "
                f"ë©”ëª¨ë¦¬: {batch_current['memory_peak_mb']:.1f}MB"
            )
            self.logger.info(
                f"ë°°ì¹˜ í¬ê¸° {batch_size} - ì˜ˆë³´: {batch_forecast['records_per_second']:.1f} records/sec, "
                f"ë©”ëª¨ë¦¬: {batch_forecast['memory_peak_mb']:.1f}MB"
            )
        
        # ê²°ê³¼ ë¶„ì„ ë° ë³´ê³ ì„œ ìƒì„±
        self.generate_performance_report()
    
    def generate_performance_report(self):
        """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±"""
        
        if not self.test_results:
            self.logger.warning("í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        report_lines = []
        report_lines.append("=" * 80)
        report_lines.append("ë°°ì¹˜ INSERT ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë³´ê³ ì„œ")
        report_lines.append(f"ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append("=" * 80)
        
        # í…Œì´ë¸” íƒ€ì…ë³„ ê²°ê³¼ ë¶„ì„
        for table_type in ["current", "forecast"]:
            type_results = [r for r in self.test_results if r["table_type"] == table_type]
            if not type_results:
                continue
                
            report_lines.append(f"\nğŸ“Š {table_type.upper()} í…Œì´ë¸” ì„±ëŠ¥ ê²°ê³¼:")
            report_lines.append("-" * 50)
            
            # ê¸°ì¡´ ë°©ì‹ ê²°ê³¼
            legacy_results = [r for r in type_results if r["method"] == "legacy"]
            if legacy_results:
                legacy = legacy_results[0]
                report_lines.append(f"ğŸ”´ ê¸°ì¡´ ë°©ì‹:")
                report_lines.append(f"   ì²˜ë¦¬ëŸ‰: {legacy['records_per_second']:.1f} records/sec")
                report_lines.append(f"   ì†Œìš”ì‹œê°„: {legacy['execution_time']:.2f}ì´ˆ")
                report_lines.append(f"   ë©”ëª¨ë¦¬ ì‚¬ìš©: {legacy['memory_peak_mb']:.1f}MB")
            
            # ë°°ì¹˜ ë°©ì‹ ê²°ê³¼
            batch_results = [r for r in type_results if r["method"] == "batch_optimized"]
            if batch_results:
                report_lines.append(f"\nğŸŸ¢ ë°°ì¹˜ ìµœì í™” ë°©ì‹:")
                
                best_performance = max(batch_results, key=lambda x: x['records_per_second'])
                best_memory = min(batch_results, key=lambda x: x['memory_peak_mb'])
                
                for result in sorted(batch_results, key=lambda x: x['batch_size']):
                    batch_size = result['batch_size']
                    rps = result['records_per_second']
                    memory = result['memory_peak_mb']
                    
                    indicator = ""
                    if result == best_performance:
                        indicator += "âš¡"
                    if result == best_memory:
                        indicator += "ğŸ’¾"
                    
                    report_lines.append(
                        f"   ë°°ì¹˜í¬ê¸° {batch_size:4d}: {rps:8.1f} records/sec, "
                        f"ë©”ëª¨ë¦¬ {memory:5.1f}MB {indicator}"
                    )
                
                # ì„±ëŠ¥ ê°œì„  ë¶„ì„
                if legacy_results:
                    legacy_rps = legacy_results[0]['records_per_second']
                    best_rps = best_performance['records_per_second']
                    improvement = (best_rps / legacy_rps - 1) * 100 if legacy_rps > 0 else 0
                    
                    report_lines.append(f"\nğŸ“ˆ ì„±ëŠ¥ ê°œì„ :")
                    report_lines.append(f"   ìµœëŒ€ ì„±ëŠ¥ í–¥ìƒ: {improvement:.1f}%")
                    report_lines.append(f"   ìµœì  ë°°ì¹˜ í¬ê¸°: {best_performance['batch_size']}")
                    report_lines.append(f"   ë©”ëª¨ë¦¬ íš¨ìœ¨ ë°°ì¹˜: {best_memory['batch_size']}")
        
        # ê¶Œì¥ì‚¬í•­
        report_lines.append("\nğŸ’¡ ê¶Œì¥ ì„¤ì •:")
        
        # ì „ì²´ ê²°ê³¼ì—ì„œ ìµœì  ë°°ì¹˜ í¬ê¸° ì°¾ê¸°
        batch_results = [r for r in self.test_results if r["method"] == "batch_optimized"]
        if batch_results:
            # ì„±ëŠ¥ê³¼ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì˜ ê· í˜•ì  ì°¾ê¸°
            scored_results = []
            for result in batch_results:
                rps_score = result['records_per_second'] / 1000  # ì •ê·œí™”
                memory_score = 50 / result['memory_peak_mb']  # ë©”ëª¨ë¦¬ëŠ” ì—­ìˆ˜ (ì ì„ìˆ˜ë¡ ì¢‹ìŒ)
                total_score = rps_score + memory_score
                scored_results.append((result, total_score))
            
            best_balance = max(scored_results, key=lambda x: x[1])[0]
            
            report_lines.append(f"   ë°°ì¹˜ í¬ê¸°: {best_balance['batch_size']}")
            report_lines.append(f"   ì˜ˆìƒ ì„±ëŠ¥: {best_balance['records_per_second']:.1f} records/sec")
            report_lines.append(f"   ë©”ëª¨ë¦¬ ì‚¬ìš©: {best_balance['memory_peak_mb']:.1f}MB")
        
        # ì¶”ê°€ ìµœì í™” ì œì•ˆ
        report_lines.append("\nğŸ”§ ì¶”ê°€ ìµœì í™” ì œì•ˆ:")
        report_lines.append("   1. ë³‘ë ¬ ì²˜ë¦¬: ì§€ì—­ë³„ ë™ì‹œ ì²˜ë¦¬ êµ¬í˜„")
        report_lines.append("   2. ì—°ê²° í’€ í™•ì¥: ìµœëŒ€ ì—°ê²° ìˆ˜ ì¦ê°€")
        report_lines.append("   3. ì¸ë±ìŠ¤ ìµœì í™”: UPSERT ëŒ€ìƒ ì»¬ëŸ¼ ì¸ë±ìŠ¤ ì¡°ì •")
        report_lines.append("   4. íŒŒí‹°ì…”ë‹: ë‚ ì§œë³„ í…Œì´ë¸” íŒŒí‹°ì…”ë‹ ê³ ë ¤")
        
        report_lines.append("\n" + "=" * 80)
        
        # ë¦¬í¬íŠ¸ ì¶œë ¥ ë° ì €ì¥
        report_content = "\n".join(report_lines)
        print(report_content)
        
        # íŒŒì¼ë¡œ ì €ì¥
        report_file = project_root / "logs" / f"batch_performance_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        report_file.parent.mkdir(exist_ok=True)
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        self.logger.info(f"ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ì €ì¥: {report_file}")


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ë°°ì¹˜ INSERT ì„±ëŠ¥ í…ŒìŠ¤íŠ¸')
    parser.add_argument('--test-size', type=int, default=1000, 
                       help='í…ŒìŠ¤íŠ¸í•  ë ˆì½”ë“œ ìˆ˜ (ê¸°ë³¸: 1000)')
    parser.add_argument('--batch-sizes', type=str, default='100,500,1000,2000',
                       help='í…ŒìŠ¤íŠ¸í•  ë°°ì¹˜ í¬ê¸°ë“¤ (ê¸°ë³¸: 100,500,1000,2000)')
    parser.add_argument('--skip-legacy', action='store_true',
                       help='ê¸°ì¡´ ë°©ì‹ í…ŒìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸°')
    
    args = parser.parse_args()
    
    # ë°°ì¹˜ í¬ê¸° íŒŒì‹±
    try:
        batch_sizes = [int(size.strip()) for size in args.batch_sizes.split(',')]
    except ValueError:
        print("âŒ ë°°ì¹˜ í¬ê¸° í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. ì˜ˆ: --batch-sizes 100,500,1000")
        return 1
    
    tester = BatchPerformanceTester()
    
    try:
        await tester.run_performance_comparison(
            test_size=args.test_size,
            batch_sizes=batch_sizes,
            skip_legacy=args.skip_legacy
        )
        
        print("âœ… ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("ğŸ“‹ ê²°ê³¼:")
        print("  1. ì„±ëŠ¥ ë¹„êµ ë¶„ì„ ì™„ë£Œ")
        print("  2. ìµœì  ë°°ì¹˜ í¬ê¸° ì‹ë³„")
        print("  3. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„")
        print("  4. ì„±ëŠ¥ ê°œì„  ê¶Œì¥ì‚¬í•­ ì œì‹œ")
        
        return 0
        
    except Exception as e:
        print(f"âŒ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)